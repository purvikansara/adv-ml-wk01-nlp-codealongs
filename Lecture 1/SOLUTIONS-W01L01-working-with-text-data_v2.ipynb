{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f34a8583-3d57-4f07-8a10-9459ee3cdb09",
   "metadata": {},
   "source": [
    "# SOLUTIONS: Advanced ML Week 1, Lecture 1: Working with and Preparing Text Data\n",
    "\n",
    "In this notebook we will be preparing Twitter (X) Tweets for sentiment analysis.  Sentiment analysis is a common text classification challenge to determine whether a text is positive or negative.  \n",
    "\n",
    "This is useful for companies that want to analyze large numbers of documents, tweets, reviews, etc., to determine public sentiment about a product or service.\n",
    "\n",
    "The data was originally gathered from Twitter (now X) and hand-labeled.  Of course there will be some human bias in the labeling.  It was downloaded from Kaggle at this site: [Kaggle Twitter Tweets Sentiment Dataset](https://www.kaggle.com/datasets/yasserh/twitter-tweets-sentiment-dataset/)\n",
    "\n",
    "There are 3 classes: positive, negative, and neutral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a6c695c-5cfd-4069-aacf-dacd0457e3d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:15:00.537963Z",
     "iopub.status.busy": "2023-12-19T01:15:00.537868Z",
     "iopub.status.idle": "2023-12-19T01:15:01.657170Z",
     "shell.execute_reply": "2023-12-19T01:15:01.656832Z",
     "shell.execute_reply.started": "2023-12-19T01:15:00.537954Z"
    }
   },
   "outputs": [],
   "source": [
    "## Import necessary packages\n",
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c0645a-3d8a-41f9-a678-23b5862ac8a2",
   "metadata": {},
   "source": [
    "# Load the Data\n",
    "\n",
    "We will download our **corpus** of tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f666473-51b7-4c60-8ce6-ae94e5b3d73f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:15:01.658445Z",
     "iopub.status.busy": "2023-12-19T01:15:01.658304Z",
     "iopub.status.idle": "2023-12-19T01:15:01.717993Z",
     "shell.execute_reply": "2023-12-19T01:15:01.717673Z",
     "shell.execute_reply.started": "2023-12-19T01:15:01.658436Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28b57f3990</td>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameles...</td>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameles...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6e0c6d75b1</td>\n",
       "      <td>2am feedings for the baby are fun when he is a...</td>\n",
       "      <td>fun</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50e14c0bb8</td>\n",
       "      <td>Soooo high</td>\n",
       "      <td>Soooo high</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>e050245fbd</td>\n",
       "      <td>Both of you</td>\n",
       "      <td>Both of you</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fc2cbefa9d</td>\n",
       "      <td>Journey!? Wow... u just became cooler.  hehe....</td>\n",
       "      <td>Wow... u just became cooler.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "5  28b57f3990  http://www.dothebouncy.com/smf - some shameles...   \n",
       "6  6e0c6d75b1  2am feedings for the baby are fun when he is a...   \n",
       "7  50e14c0bb8                                         Soooo high   \n",
       "8  e050245fbd                                        Both of you   \n",
       "9  fc2cbefa9d   Journey!? Wow... u just became cooler.  hehe....   \n",
       "\n",
       "                                       selected_text sentiment  \n",
       "0                I`d have responded, if I were going   neutral  \n",
       "1                                           Sooo SAD  negative  \n",
       "2                                        bullying me  negative  \n",
       "3                                     leave me alone  negative  \n",
       "4                                      Sons of ****,  negative  \n",
       "5  http://www.dothebouncy.com/smf - some shameles...   neutral  \n",
       "6                                                fun  positive  \n",
       "7                                         Soooo high   neutral  \n",
       "8                                        Both of you   neutral  \n",
       "9                       Wow... u just became cooler.  positive  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Download corpus of tweets\n",
    "df = pd.read_csv('../Data/archive.zip')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15206203-a97b-448d-b5e9-a95c511ec56a",
   "metadata": {},
   "source": [
    "# Some light EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12e60c31-28a8-48a2-a150-cc2eb9ed3f24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:15:01.718664Z",
     "iopub.status.busy": "2023-12-19T01:15:01.718557Z",
     "iopub.status.idle": "2023-12-19T01:15:01.730876Z",
     "shell.execute_reply": "2023-12-19T01:15:01.730283Z",
     "shell.execute_reply.started": "2023-12-19T01:15:01.718654Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27481 entries, 0 to 27480\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   textID         27481 non-null  object\n",
      " 1   text           27480 non-null  object\n",
      " 2   selected_text  27480 non-null  object\n",
      " 3   sentiment      27481 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 858.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc3e96d1-975b-493b-9551-9e242871df7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:15:01.731778Z",
     "iopub.status.busy": "2023-12-19T01:15:01.731609Z",
     "iopub.status.idle": "2023-12-19T01:15:01.742631Z",
     "shell.execute_reply": "2023-12-19T01:15:01.742238Z",
     "shell.execute_reply.started": "2023-12-19T01:15:01.731767Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafde953-8792-47b9-861e-3f53b6e3a177",
   "metadata": {},
   "source": [
    "# Some Light Data Cleaning\n",
    "\n",
    "We see that our **corpus** has 27481 **documents**, each with an ID, the full text, a shortened version, and the labeled sentiment.\n",
    "\n",
    "Interestingly, one of the tweets has no text!  We definitely want to get rid of that.  We will also drop the `textID` and `selected_text` columns.  We are going to use the entire text of each tweet, not just a subset.\n",
    "\n",
    "We will keep the label, `sentiment` for later classification and analysis tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64be5747-3e29-4745-ab38-c25e09255dd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:15:01.743502Z",
     "iopub.status.busy": "2023-12-19T01:15:01.743294Z",
     "iopub.status.idle": "2023-12-19T01:15:01.757348Z",
     "shell.execute_reply": "2023-12-19T01:15:01.756975Z",
     "shell.execute_reply.started": "2023-12-19T01:15:01.743483Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns=['textID', 'selected_text'])\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbbbcd7d-1e2f-4d44-bb98-43ece33d3ef7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:15:01.758108Z",
     "iopub.status.busy": "2023-12-19T01:15:01.757973Z",
     "iopub.status.idle": "2023-12-19T01:15:01.767335Z",
     "shell.execute_reply": "2023-12-19T01:15:01.766744Z",
     "shell.execute_reply.started": "2023-12-19T01:15:01.758097Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 27480 entries, 0 to 27480\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   text       27480 non-null  object\n",
      " 1   sentiment  27480 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 644.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922b390c-c90c-46d4-be9f-061e8a66f2f2",
   "metadata": {},
   "source": [
    "# Some More EDA\n",
    "Let's look at some aspects of this text.\n",
    "* What do the **documents** look like?\n",
    "* How long do the tend to be?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0656c034-5ce8-4214-8147-a18f1150699f",
   "metadata": {},
   "source": [
    "## View some sample tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f2e8add-e130-49ac-8ffa-9dcb7d59568d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:15:01.769790Z",
     "iopub.status.busy": "2023-12-19T01:15:01.769630Z",
     "iopub.status.idle": "2023-12-19T01:15:01.774276Z",
     "shell.execute_reply": "2023-12-19T01:15:01.773694Z",
     "shell.execute_reply.started": "2023-12-19T01:15:01.769780Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                             I`d have responded, if I were going\n",
       "1                                                   Sooo SAD I will miss you here in San Diego!!!\n",
       "2                                                                       my boss is bullying me...\n",
       "3                                                                  what interview! leave me alone\n",
       "4                      Sons of ****, why couldn`t they put them on the releases we already bought\n",
       "5    http://www.dothebouncy.com/smf - some shameless plugging for the best Rangers forum on earth\n",
       "6                                2am feedings for the baby are fun when he is all smiles and coos\n",
       "7                                                                                      Soooo high\n",
       "8                                                                                     Both of you\n",
       "9                            Journey!? Wow... u just became cooler.  hehe... (is that possible!?)\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Expand how many characters pandas will show\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "## Display some of the documents (tweets)\n",
    "df['text'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4b7b84-fbab-4756-a8cc-2eec49dc0389",
   "metadata": {},
   "source": [
    "We see a URL in here.  This is a problem for normalization, since those are going to be unique and not covered by stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc165bb-baf3-4500-bc58-8b139812db70",
   "metadata": {},
   "source": [
    "## URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1f7bdcd-4287-4ca5-b59f-1a289d3a4aac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:15:01.774972Z",
     "iopub.status.busy": "2023-12-19T01:15:01.774820Z",
     "iopub.status.idle": "2023-12-19T01:15:01.786990Z",
     "shell.execute_reply": "2023-12-19T01:15:01.786676Z",
     "shell.execute_reply.started": "2023-12-19T01:15:01.774962Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameless plugging for the best Rangers forum on earth</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>i`ve been sick for the past few days  and thus, my hair looks wierd.  if i didnt have a hat on it would look... http://tinyurl.com/mnf4kw</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Thats it, its the end. Tears for Fears vs Eric Prydz, DJ Hero   http://bit.ly/2Hpbg4</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Then you should check out http://twittersucks.com and connect with other tweeple who hate twitter</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>will be back later.  http://plurk.com/p/rp3k7</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27374</th>\n",
       "      <td>says Finally, Im home.  http://plurk.com/p/rr121</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27384</th>\n",
       "      <td>This is a much better tool than some I have come across http://www.tweepular.com - Twitter Karma on Steroids</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27386</th>\n",
       "      <td>#vwll2009 Would one of the VWLLers want to add this event to our Ning?   http://bit.ly/BF5sh  Would much appreciate that</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27463</th>\n",
       "      <td>LIKE DREW SAID 'GIVE TC A CHANCE' WE WILL MISS THOMAS  BUT HAVE TO MOVE ON. SO WATCH THIS! http://bit.ly/r6RfC</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27472</th>\n",
       "      <td>http://twitpic.com/663vr - Wanted to visit the animals but we were too late</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1220 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                            text  \\\n",
       "5                                                   http://www.dothebouncy.com/smf - some shameless plugging for the best Rangers forum on earth   \n",
       "17     i`ve been sick for the past few days  and thus, my hair looks wierd.  if i didnt have a hat on it would look... http://tinyurl.com/mnf4kw   \n",
       "35                                                          Thats it, its the end. Tears for Fears vs Eric Prydz, DJ Hero   http://bit.ly/2Hpbg4   \n",
       "50                                             Then you should check out http://twittersucks.com and connect with other tweeple who hate twitter   \n",
       "57                                                                                                 will be back later.  http://plurk.com/p/rp3k7   \n",
       "...                                                                                                                                          ...   \n",
       "27374                                                                                           says Finally, Im home.  http://plurk.com/p/rr121   \n",
       "27384                               This is a much better tool than some I have come across http://www.tweepular.com - Twitter Karma on Steroids   \n",
       "27386                   #vwll2009 Would one of the VWLLers want to add this event to our Ning?   http://bit.ly/BF5sh  Would much appreciate that   \n",
       "27463                             LIKE DREW SAID 'GIVE TC A CHANCE' WE WILL MISS THOMAS  BUT HAVE TO MOVE ON. SO WATCH THIS! http://bit.ly/r6RfC   \n",
       "27472                                                                http://twitpic.com/663vr - Wanted to visit the animals but we were too late   \n",
       "\n",
       "      sentiment  \n",
       "5       neutral  \n",
       "17     negative  \n",
       "35      neutral  \n",
       "50      neutral  \n",
       "57      neutral  \n",
       "...         ...  \n",
       "27374   neutral  \n",
       "27384  positive  \n",
       "27386  positive  \n",
       "27463  negative  \n",
       "27472  negative  \n",
       "\n",
       "[1220 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['text'].str.contains('http://')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930cd2bd-5fbf-4d38-b932-05ae2de1e25e",
   "metadata": {},
   "source": [
    "## Get some statistics on the length of **documents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e65b4f6-78ec-4344-aca0-83c43a78336b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:15:01.787777Z",
     "iopub.status.busy": "2023-12-19T01:15:01.787555Z",
     "iopub.status.idle": "2023-12-19T01:15:01.796098Z",
     "shell.execute_reply": "2023-12-19T01:15:01.795742Z",
     "shell.execute_reply.started": "2023-12-19T01:15:01.787763Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>negative</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>negative</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on the releases we already bought</td>\n",
       "      <td>negative</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameless plugging for the best Rangers forum on earth</td>\n",
       "      <td>neutral</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2am feedings for the baby are fun when he is all smiles and coos</td>\n",
       "      <td>positive</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Soooo high</td>\n",
       "      <td>neutral</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Both of you</td>\n",
       "      <td>neutral</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Journey!? Wow... u just became cooler.  hehe... (is that possible!?)</td>\n",
       "      <td>positive</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                           text  \\\n",
       "0                                                           I`d have responded, if I were going   \n",
       "1                                                 Sooo SAD I will miss you here in San Diego!!!   \n",
       "2                                                                     my boss is bullying me...   \n",
       "3                                                                what interview! leave me alone   \n",
       "4                    Sons of ****, why couldn`t they put them on the releases we already bought   \n",
       "5  http://www.dothebouncy.com/smf - some shameless plugging for the best Rangers forum on earth   \n",
       "6                              2am feedings for the baby are fun when he is all smiles and coos   \n",
       "7                                                                                    Soooo high   \n",
       "8                                                                                   Both of you   \n",
       "9                          Journey!? Wow... u just became cooler.  hehe... (is that possible!?)   \n",
       "\n",
       "  sentiment  length  \n",
       "0   neutral      36  \n",
       "1  negative      46  \n",
       "2  negative      25  \n",
       "3  negative      31  \n",
       "4  negative      75  \n",
       "5   neutral      92  \n",
       "6  positive      64  \n",
       "7   neutral      10  \n",
       "8   neutral      12  \n",
       "9  positive      69  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Determine the length of each tweet\n",
    "df['length'] = df['text'].map(len)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62170df2-9dda-479d-b003-37a401889bc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:15:01.796850Z",
     "iopub.status.busy": "2023-12-19T01:15:01.796738Z",
     "iopub.status.idle": "2023-12-19T01:15:01.802325Z",
     "shell.execute_reply": "2023-12-19T01:15:01.802001Z",
     "shell.execute_reply.started": "2023-12-19T01:15:01.796840Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    27480.000000\n",
       "mean        68.330022\n",
       "std         35.603870\n",
       "min          3.000000\n",
       "25%         39.000000\n",
       "50%         64.000000\n",
       "75%         97.000000\n",
       "max        141.000000\n",
       "Name: length, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Analyze the statistics of the lengths\n",
    "df['length'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45dafca-dc80-4cba-862d-e9ba98de19dd",
   "metadata": {},
   "source": [
    "The tweets have an mean length of 68 characters and a median of 64. They range from 3 to 141 characters with a standard deviation of 35.  The middle 50% are between 39 and 97 characters in length.\n",
    "\n",
    "This gives us some idea of how long they tend to be."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8f7818-5a2e-48f2-87bf-29678b7f9be6",
   "metadata": {},
   "source": [
    "# Text Normalization with NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a869f6-073e-4281-b21a-33aba2fdd553",
   "metadata": {},
   "source": [
    "## Normalizing Casing\n",
    "\n",
    "It's common practice to lower the casing of the text in our documents to contribut to normalizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "550db04b-32a7-4270-9420-e6da4eaadb1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:15:01.803252Z",
     "iopub.status.busy": "2023-12-19T01:15:01.803073Z",
     "iopub.status.idle": "2023-12-19T01:15:01.811631Z",
     "shell.execute_reply": "2023-12-19T01:15:01.811222Z",
     "shell.execute_reply.started": "2023-12-19T01:15:01.803240Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>length</th>\n",
       "      <th>lower_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>36</td>\n",
       "      <td>i`d have responded, if i were going</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>negative</td>\n",
       "      <td>46</td>\n",
       "      <td>sooo sad i will miss you here in san diego!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>negative</td>\n",
       "      <td>25</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>31</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on the releases we already bought</td>\n",
       "      <td>negative</td>\n",
       "      <td>75</td>\n",
       "      <td>sons of ****, why couldn`t they put them on the releases we already bought</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                          text  \\\n",
       "0                                          I`d have responded, if I were going   \n",
       "1                                Sooo SAD I will miss you here in San Diego!!!   \n",
       "2                                                    my boss is bullying me...   \n",
       "3                                               what interview! leave me alone   \n",
       "4   Sons of ****, why couldn`t they put them on the releases we already bought   \n",
       "\n",
       "  sentiment  length  \\\n",
       "0   neutral      36   \n",
       "1  negative      46   \n",
       "2  negative      25   \n",
       "3  negative      31   \n",
       "4  negative      75   \n",
       "\n",
       "                                                                    lower_text  \n",
       "0                                          i`d have responded, if i were going  \n",
       "1                                sooo sad i will miss you here in san diego!!!  \n",
       "2                                                    my boss is bullying me...  \n",
       "3                                               what interview! leave me alone  \n",
       "4   sons of ****, why couldn`t they put them on the releases we already bought  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lower_text'] = df['text'].str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b174777b-b52a-4260-b486-b75ec1a2ba0f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Tokenizing\n",
    "\n",
    "Tokenizing text into single word tokens is simple in Python.  We can just use `str.split()`.  The default separator for `.split()` is one space, so `' '`.\n",
    "\n",
    "We can access Pandas' string accessor with `df.str.<method>`.  This allows us to apply string methods to all rows in a column.\n",
    "\n",
    "When processing text, if memory allows, it can be useful to keep many versions of your text: tokenize, lemmatized, no stop words, etc.  Some analysis or modeling packages expect tokenized data and others do not.  We often want to use different versions for different kinds of analysis, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b244d34-3f00-4b0a-af13-d9f0ee324398",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:15:01.812172Z",
     "iopub.status.busy": "2023-12-19T01:15:01.812075Z",
     "iopub.status.idle": "2023-12-19T01:15:01.839166Z",
     "shell.execute_reply": "2023-12-19T01:15:01.838751Z",
     "shell.execute_reply.started": "2023-12-19T01:15:01.812163Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>length</th>\n",
       "      <th>lower_text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>36</td>\n",
       "      <td>i`d have responded, if i were going</td>\n",
       "      <td>[i`d, have, responded,, if, i, were, going]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>negative</td>\n",
       "      <td>46</td>\n",
       "      <td>sooo sad i will miss you here in san diego!!!</td>\n",
       "      <td>[sooo, sad, i, will, miss, you, here, in, san, diego!!!]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>negative</td>\n",
       "      <td>25</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>[my, boss, is, bullying, me...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>31</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>[what, interview!, leave, me, alone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on the releases we already bought</td>\n",
       "      <td>negative</td>\n",
       "      <td>75</td>\n",
       "      <td>sons of ****, why couldn`t they put them on the releases we already bought</td>\n",
       "      <td>[sons, of, ****,, why, couldn`t, they, put, them, on, the, releases, we, already, bought]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                          text  \\\n",
       "0                                          I`d have responded, if I were going   \n",
       "1                                Sooo SAD I will miss you here in San Diego!!!   \n",
       "2                                                    my boss is bullying me...   \n",
       "3                                               what interview! leave me alone   \n",
       "4   Sons of ****, why couldn`t they put them on the releases we already bought   \n",
       "\n",
       "  sentiment  length  \\\n",
       "0   neutral      36   \n",
       "1  negative      46   \n",
       "2  negative      25   \n",
       "3  negative      31   \n",
       "4  negative      75   \n",
       "\n",
       "                                                                    lower_text  \\\n",
       "0                                          i`d have responded, if i were going   \n",
       "1                                sooo sad i will miss you here in san diego!!!   \n",
       "2                                                    my boss is bullying me...   \n",
       "3                                               what interview! leave me alone   \n",
       "4   sons of ****, why couldn`t they put them on the releases we already bought   \n",
       "\n",
       "                                                                                      tokens  \n",
       "0                                                [i`d, have, responded,, if, i, were, going]  \n",
       "1                                   [sooo, sad, i, will, miss, you, here, in, san, diego!!!]  \n",
       "2                                                            [my, boss, is, bullying, me...]  \n",
       "3                                                       [what, interview!, leave, me, alone]  \n",
       "4  [sons, of, ****,, why, couldn`t, they, put, them, on, the, releases, we, already, bought]  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokens'] = df['lower_text'].str.split()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68391d27-b08b-469a-b5cc-c2571b849b14",
   "metadata": {},
   "source": [
    "### Better way to tokenize data\n",
    "\n",
    "NLTK has a more sophisticated tokenization function that will isolate things like punctuation as well.  This way 'hooray' and 'hooray!!!' will be the same token.\n",
    "\n",
    "In order for NLTK to recognize the punctuation, we will need to download the 'punkt' data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99cb8036-ffbe-4365-aacc-3ee5cc5e05e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:15:01.839867Z",
     "iopub.status.busy": "2023-12-19T01:15:01.839770Z",
     "iopub.status.idle": "2023-12-19T01:15:03.937375Z",
     "shell.execute_reply": "2023-12-19T01:15:03.937083Z",
     "shell.execute_reply.started": "2023-12-19T01:15:01.839858Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/codingdojo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>length</th>\n",
       "      <th>lower_text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>36</td>\n",
       "      <td>i`d have responded, if i were going</td>\n",
       "      <td>[i, `, d, have, responded, ,, if, i, were, going]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>negative</td>\n",
       "      <td>46</td>\n",
       "      <td>sooo sad i will miss you here in san diego!!!</td>\n",
       "      <td>[sooo, sad, i, will, miss, you, here, in, san, diego, !, !, !]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>negative</td>\n",
       "      <td>25</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>[my, boss, is, bullying, me, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>31</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>[what, interview, !, leave, me, alone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on the releases we already bought</td>\n",
       "      <td>negative</td>\n",
       "      <td>75</td>\n",
       "      <td>sons of ****, why couldn`t they put them on the releases we already bought</td>\n",
       "      <td>[sons, of, *, *, *, *, ,, why, couldn, `, t, they, put, them, on, the, releases, we, already, bought]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                          text  \\\n",
       "0                                          I`d have responded, if I were going   \n",
       "1                                Sooo SAD I will miss you here in San Diego!!!   \n",
       "2                                                    my boss is bullying me...   \n",
       "3                                               what interview! leave me alone   \n",
       "4   Sons of ****, why couldn`t they put them on the releases we already bought   \n",
       "\n",
       "  sentiment  length  \\\n",
       "0   neutral      36   \n",
       "1  negative      46   \n",
       "2  negative      25   \n",
       "3  negative      31   \n",
       "4  negative      75   \n",
       "\n",
       "                                                                    lower_text  \\\n",
       "0                                          i`d have responded, if i were going   \n",
       "1                                sooo sad i will miss you here in san diego!!!   \n",
       "2                                                    my boss is bullying me...   \n",
       "3                                               what interview! leave me alone   \n",
       "4   sons of ****, why couldn`t they put them on the releases we already bought   \n",
       "\n",
       "                                                                                                  tokens  \n",
       "0                                                      [i, `, d, have, responded, ,, if, i, were, going]  \n",
       "1                                         [sooo, sad, i, will, miss, you, here, in, san, diego, !, !, !]  \n",
       "2                                                                      [my, boss, is, bullying, me, ...]  \n",
       "3                                                                 [what, interview, !, leave, me, alone]  \n",
       "4  [sons, of, *, *, *, *, ,, why, couldn, `, t, they, put, them, on, the, releases, we, already, bought]  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Download punkt\n",
    "nltk.download('punkt')\n",
    "\n",
    "df['tokens'] = df['lower_text'].apply(nltk.word_tokenize)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92f435f-e144-4b72-8c07-3249dae5b164",
   "metadata": {},
   "source": [
    "## Remove Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32e91158-047d-4ba7-9a6b-67ae623a33b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:15:03.938051Z",
     "iopub.status.busy": "2023-12-19T01:15:03.937953Z",
     "iopub.status.idle": "2023-12-19T01:15:03.945027Z",
     "shell.execute_reply": "2023-12-19T01:15:03.944677Z",
     "shell.execute_reply.started": "2023-12-19T01:15:03.938042Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/codingdojo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Download NLTK stopword list\n",
    "nltk.download('stopwords')\n",
    "\n",
    "## Load the English stop words.\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "stop_words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b32bd5a-fe7d-4766-baec-55ceb0f2f78c",
   "metadata": {},
   "source": [
    "<font color=red> NOTICE </font> that all of the stop words are lower case.  It's necessary to ensure that your tokens are all lower case before using this list to remove stop words.\n",
    "\n",
    "To remove the stop words from each document, we will apply a function that will check each word in the list of tokens against the list of stopwords and remove them if they are in the list.  More specifically, it will only save them if they are NOT in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b7cd190-07ee-40ee-b6c2-4c8639ff4cf9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:15:03.946000Z",
     "iopub.status.busy": "2023-12-19T01:15:03.945797Z",
     "iopub.status.idle": "2023-12-19T01:15:04.445918Z",
     "shell.execute_reply": "2023-12-19T01:15:04.445561Z",
     "shell.execute_reply.started": "2023-12-19T01:15:03.945986Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>length</th>\n",
       "      <th>lower_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>no_stops</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>36</td>\n",
       "      <td>i`d have responded, if i were going</td>\n",
       "      <td>[i, `, d, have, responded, ,, if, i, were, going]</td>\n",
       "      <td>[`, responded, ,, going]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>negative</td>\n",
       "      <td>46</td>\n",
       "      <td>sooo sad i will miss you here in san diego!!!</td>\n",
       "      <td>[sooo, sad, i, will, miss, you, here, in, san, diego, !, !, !]</td>\n",
       "      <td>[sooo, sad, miss, san, diego, !, !, !]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>negative</td>\n",
       "      <td>25</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>[my, boss, is, bullying, me, ...]</td>\n",
       "      <td>[boss, bullying, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>31</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>[what, interview, !, leave, me, alone]</td>\n",
       "      <td>[interview, !, leave, alone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on the releases we already bought</td>\n",
       "      <td>negative</td>\n",
       "      <td>75</td>\n",
       "      <td>sons of ****, why couldn`t they put them on the releases we already bought</td>\n",
       "      <td>[sons, of, *, *, *, *, ,, why, couldn, `, t, they, put, them, on, the, releases, we, already, bought]</td>\n",
       "      <td>[sons, *, *, *, *, ,, `, put, releases, already, bought]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                          text  \\\n",
       "0                                          I`d have responded, if I were going   \n",
       "1                                Sooo SAD I will miss you here in San Diego!!!   \n",
       "2                                                    my boss is bullying me...   \n",
       "3                                               what interview! leave me alone   \n",
       "4   Sons of ****, why couldn`t they put them on the releases we already bought   \n",
       "\n",
       "  sentiment  length  \\\n",
       "0   neutral      36   \n",
       "1  negative      46   \n",
       "2  negative      25   \n",
       "3  negative      31   \n",
       "4  negative      75   \n",
       "\n",
       "                                                                    lower_text  \\\n",
       "0                                          i`d have responded, if i were going   \n",
       "1                                sooo sad i will miss you here in san diego!!!   \n",
       "2                                                    my boss is bullying me...   \n",
       "3                                               what interview! leave me alone   \n",
       "4   sons of ****, why couldn`t they put them on the releases we already bought   \n",
       "\n",
       "                                                                                                  tokens  \\\n",
       "0                                                      [i, `, d, have, responded, ,, if, i, were, going]   \n",
       "1                                         [sooo, sad, i, will, miss, you, here, in, san, diego, !, !, !]   \n",
       "2                                                                      [my, boss, is, bullying, me, ...]   \n",
       "3                                                                 [what, interview, !, leave, me, alone]   \n",
       "4  [sons, of, *, *, *, *, ,, why, couldn, `, t, they, put, them, on, the, releases, we, already, bought]   \n",
       "\n",
       "                                                   no_stops  \n",
       "0                                  [`, responded, ,, going]  \n",
       "1                    [sooo, sad, miss, san, diego, !, !, !]  \n",
       "2                                     [boss, bullying, ...]  \n",
       "3                              [interview, !, leave, alone]  \n",
       "4  [sons, *, *, *, *, ,, `, put, releases, already, bought]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## [V1 List Comp] Remove Stopwords Function\n",
    "def remove_stopwords(tokens):\n",
    "    no_stops = [token for token in tokens if not token in stop_words]\n",
    "    return no_stops\n",
    "\n",
    "df['no_stops'] = df['tokens'].map(remove_stopwords)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9cea6be-ebc8-4903-adaa-4d65154a5866",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:15:04.446506Z",
     "iopub.status.busy": "2023-12-19T01:15:04.446402Z",
     "iopub.status.idle": "2023-12-19T01:15:05.014820Z",
     "shell.execute_reply": "2023-12-19T01:15:05.014460Z",
     "shell.execute_reply.started": "2023-12-19T01:15:04.446497Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>length</th>\n",
       "      <th>lower_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>no_stops</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>36</td>\n",
       "      <td>i`d have responded, if i were going</td>\n",
       "      <td>[i, `, d, have, responded, ,, if, i, were, going]</td>\n",
       "      <td>[`, responded, ,, going]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>negative</td>\n",
       "      <td>46</td>\n",
       "      <td>sooo sad i will miss you here in san diego!!!</td>\n",
       "      <td>[sooo, sad, i, will, miss, you, here, in, san, diego, !, !, !]</td>\n",
       "      <td>[sooo, sad, miss, san, diego, !, !, !]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>negative</td>\n",
       "      <td>25</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>[my, boss, is, bullying, me, ...]</td>\n",
       "      <td>[boss, bullying, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>31</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>[what, interview, !, leave, me, alone]</td>\n",
       "      <td>[interview, !, leave, alone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on the releases we already bought</td>\n",
       "      <td>negative</td>\n",
       "      <td>75</td>\n",
       "      <td>sons of ****, why couldn`t they put them on the releases we already bought</td>\n",
       "      <td>[sons, of, *, *, *, *, ,, why, couldn, `, t, they, put, them, on, the, releases, we, already, bought]</td>\n",
       "      <td>[sons, *, *, *, *, ,, `, put, releases, already, bought]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameless plugging for the best Rangers forum on earth</td>\n",
       "      <td>neutral</td>\n",
       "      <td>92</td>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameless plugging for the best rangers forum on earth</td>\n",
       "      <td>[http, :, //www.dothebouncy.com/smf, -, some, shameless, plugging, for, the, best, rangers, forum, on, earth]</td>\n",
       "      <td>[http, :, //www.dothebouncy.com/smf, -, shameless, plugging, best, rangers, forum, earth]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2am feedings for the baby are fun when he is all smiles and coos</td>\n",
       "      <td>positive</td>\n",
       "      <td>64</td>\n",
       "      <td>2am feedings for the baby are fun when he is all smiles and coos</td>\n",
       "      <td>[2am, feedings, for, the, baby, are, fun, when, he, is, all, smiles, and, coos]</td>\n",
       "      <td>[2am, feedings, baby, fun, smiles, coos]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Soooo high</td>\n",
       "      <td>neutral</td>\n",
       "      <td>10</td>\n",
       "      <td>soooo high</td>\n",
       "      <td>[soooo, high]</td>\n",
       "      <td>[soooo, high]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Both of you</td>\n",
       "      <td>neutral</td>\n",
       "      <td>12</td>\n",
       "      <td>both of you</td>\n",
       "      <td>[both, of, you]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Journey!? Wow... u just became cooler.  hehe... (is that possible!?)</td>\n",
       "      <td>positive</td>\n",
       "      <td>69</td>\n",
       "      <td>journey!? wow... u just became cooler.  hehe... (is that possible!?)</td>\n",
       "      <td>[journey, !, ?, wow, ..., u, just, became, cooler, ., hehe, ..., (, is, that, possible, !, ?, )]</td>\n",
       "      <td>[journey, !, ?, wow, ..., u, became, cooler, ., hehe, ..., (, possible, !, ?, )]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                           text  \\\n",
       "0                                                           I`d have responded, if I were going   \n",
       "1                                                 Sooo SAD I will miss you here in San Diego!!!   \n",
       "2                                                                     my boss is bullying me...   \n",
       "3                                                                what interview! leave me alone   \n",
       "4                    Sons of ****, why couldn`t they put them on the releases we already bought   \n",
       "5  http://www.dothebouncy.com/smf - some shameless plugging for the best Rangers forum on earth   \n",
       "6                              2am feedings for the baby are fun when he is all smiles and coos   \n",
       "7                                                                                    Soooo high   \n",
       "8                                                                                   Both of you   \n",
       "9                          Journey!? Wow... u just became cooler.  hehe... (is that possible!?)   \n",
       "\n",
       "  sentiment  length  \\\n",
       "0   neutral      36   \n",
       "1  negative      46   \n",
       "2  negative      25   \n",
       "3  negative      31   \n",
       "4  negative      75   \n",
       "5   neutral      92   \n",
       "6  positive      64   \n",
       "7   neutral      10   \n",
       "8   neutral      12   \n",
       "9  positive      69   \n",
       "\n",
       "                                                                                     lower_text  \\\n",
       "0                                                           i`d have responded, if i were going   \n",
       "1                                                 sooo sad i will miss you here in san diego!!!   \n",
       "2                                                                     my boss is bullying me...   \n",
       "3                                                                what interview! leave me alone   \n",
       "4                    sons of ****, why couldn`t they put them on the releases we already bought   \n",
       "5  http://www.dothebouncy.com/smf - some shameless plugging for the best rangers forum on earth   \n",
       "6                              2am feedings for the baby are fun when he is all smiles and coos   \n",
       "7                                                                                    soooo high   \n",
       "8                                                                                   both of you   \n",
       "9                          journey!? wow... u just became cooler.  hehe... (is that possible!?)   \n",
       "\n",
       "                                                                                                          tokens  \\\n",
       "0                                                              [i, `, d, have, responded, ,, if, i, were, going]   \n",
       "1                                                 [sooo, sad, i, will, miss, you, here, in, san, diego, !, !, !]   \n",
       "2                                                                              [my, boss, is, bullying, me, ...]   \n",
       "3                                                                         [what, interview, !, leave, me, alone]   \n",
       "4          [sons, of, *, *, *, *, ,, why, couldn, `, t, they, put, them, on, the, releases, we, already, bought]   \n",
       "5  [http, :, //www.dothebouncy.com/smf, -, some, shameless, plugging, for, the, best, rangers, forum, on, earth]   \n",
       "6                                [2am, feedings, for, the, baby, are, fun, when, he, is, all, smiles, and, coos]   \n",
       "7                                                                                                  [soooo, high]   \n",
       "8                                                                                                [both, of, you]   \n",
       "9               [journey, !, ?, wow, ..., u, just, became, cooler, ., hehe, ..., (, is, that, possible, !, ?, )]   \n",
       "\n",
       "                                                                                    no_stops  \n",
       "0                                                                   [`, responded, ,, going]  \n",
       "1                                                     [sooo, sad, miss, san, diego, !, !, !]  \n",
       "2                                                                      [boss, bullying, ...]  \n",
       "3                                                               [interview, !, leave, alone]  \n",
       "4                                   [sons, *, *, *, *, ,, `, put, releases, already, bought]  \n",
       "5  [http, :, //www.dothebouncy.com/smf, -, shameless, plugging, best, rangers, forum, earth]  \n",
       "6                                                   [2am, feedings, baby, fun, smiles, coos]  \n",
       "7                                                                              [soooo, high]  \n",
       "8                                                                                         []  \n",
       "9           [journey, !, ?, wow, ..., u, became, cooler, ., hehe, ..., (, possible, !, ?, )]  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## [V2 For Loop] Remove Stopwords Function\n",
    "def remove_stopwords(tokens):\n",
    "    no_stops = []\n",
    "    for token in tokens:\n",
    "        if token not in stop_words:\n",
    "            no_stops.append(token)            \n",
    "    return no_stops\n",
    "\n",
    "df['no_stops'] = df['tokens'].map(remove_stopwords)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad69e4ad-4d07-43ae-903b-12c33d4b696b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:15:05.015442Z",
     "iopub.status.busy": "2023-12-19T01:15:05.015348Z",
     "iopub.status.idle": "2023-12-19T01:15:05.518906Z",
     "shell.execute_reply": "2023-12-19T01:15:05.518578Z",
     "shell.execute_reply.started": "2023-12-19T01:15:05.015434Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>length</th>\n",
       "      <th>lower_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>no_stops</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>36</td>\n",
       "      <td>i`d have responded, if i were going</td>\n",
       "      <td>[i, `, d, have, responded, ,, if, i, were, going]</td>\n",
       "      <td>[`, responded, ,, going]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>negative</td>\n",
       "      <td>46</td>\n",
       "      <td>sooo sad i will miss you here in san diego!!!</td>\n",
       "      <td>[sooo, sad, i, will, miss, you, here, in, san, diego, !, !, !]</td>\n",
       "      <td>[sooo, sad, miss, san, diego, !, !, !]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>negative</td>\n",
       "      <td>25</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>[my, boss, is, bullying, me, ...]</td>\n",
       "      <td>[boss, bullying, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>31</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>[what, interview, !, leave, me, alone]</td>\n",
       "      <td>[interview, !, leave, alone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on the releases we already bought</td>\n",
       "      <td>negative</td>\n",
       "      <td>75</td>\n",
       "      <td>sons of ****, why couldn`t they put them on the releases we already bought</td>\n",
       "      <td>[sons, of, *, *, *, *, ,, why, couldn, `, t, they, put, them, on, the, releases, we, already, bought]</td>\n",
       "      <td>[sons, *, *, *, *, ,, `, put, releases, already, bought]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameless plugging for the best Rangers forum on earth</td>\n",
       "      <td>neutral</td>\n",
       "      <td>92</td>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameless plugging for the best rangers forum on earth</td>\n",
       "      <td>[http, :, //www.dothebouncy.com/smf, -, some, shameless, plugging, for, the, best, rangers, forum, on, earth]</td>\n",
       "      <td>[http, :, //www.dothebouncy.com/smf, -, shameless, plugging, best, rangers, forum, earth]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2am feedings for the baby are fun when he is all smiles and coos</td>\n",
       "      <td>positive</td>\n",
       "      <td>64</td>\n",
       "      <td>2am feedings for the baby are fun when he is all smiles and coos</td>\n",
       "      <td>[2am, feedings, for, the, baby, are, fun, when, he, is, all, smiles, and, coos]</td>\n",
       "      <td>[2am, feedings, baby, fun, smiles, coos]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Soooo high</td>\n",
       "      <td>neutral</td>\n",
       "      <td>10</td>\n",
       "      <td>soooo high</td>\n",
       "      <td>[soooo, high]</td>\n",
       "      <td>[soooo, high]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Both of you</td>\n",
       "      <td>neutral</td>\n",
       "      <td>12</td>\n",
       "      <td>both of you</td>\n",
       "      <td>[both, of, you]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Journey!? Wow... u just became cooler.  hehe... (is that possible!?)</td>\n",
       "      <td>positive</td>\n",
       "      <td>69</td>\n",
       "      <td>journey!? wow... u just became cooler.  hehe... (is that possible!?)</td>\n",
       "      <td>[journey, !, ?, wow, ..., u, just, became, cooler, ., hehe, ..., (, is, that, possible, !, ?, )]</td>\n",
       "      <td>[journey, !, ?, wow, ..., u, became, cooler, ., hehe, ..., (, possible, !, ?, )]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                           text  \\\n",
       "0                                                           I`d have responded, if I were going   \n",
       "1                                                 Sooo SAD I will miss you here in San Diego!!!   \n",
       "2                                                                     my boss is bullying me...   \n",
       "3                                                                what interview! leave me alone   \n",
       "4                    Sons of ****, why couldn`t they put them on the releases we already bought   \n",
       "5  http://www.dothebouncy.com/smf - some shameless plugging for the best Rangers forum on earth   \n",
       "6                              2am feedings for the baby are fun when he is all smiles and coos   \n",
       "7                                                                                    Soooo high   \n",
       "8                                                                                   Both of you   \n",
       "9                          Journey!? Wow... u just became cooler.  hehe... (is that possible!?)   \n",
       "\n",
       "  sentiment  length  \\\n",
       "0   neutral      36   \n",
       "1  negative      46   \n",
       "2  negative      25   \n",
       "3  negative      31   \n",
       "4  negative      75   \n",
       "5   neutral      92   \n",
       "6  positive      64   \n",
       "7   neutral      10   \n",
       "8   neutral      12   \n",
       "9  positive      69   \n",
       "\n",
       "                                                                                     lower_text  \\\n",
       "0                                                           i`d have responded, if i were going   \n",
       "1                                                 sooo sad i will miss you here in san diego!!!   \n",
       "2                                                                     my boss is bullying me...   \n",
       "3                                                                what interview! leave me alone   \n",
       "4                    sons of ****, why couldn`t they put them on the releases we already bought   \n",
       "5  http://www.dothebouncy.com/smf - some shameless plugging for the best rangers forum on earth   \n",
       "6                              2am feedings for the baby are fun when he is all smiles and coos   \n",
       "7                                                                                    soooo high   \n",
       "8                                                                                   both of you   \n",
       "9                          journey!? wow... u just became cooler.  hehe... (is that possible!?)   \n",
       "\n",
       "                                                                                                          tokens  \\\n",
       "0                                                              [i, `, d, have, responded, ,, if, i, were, going]   \n",
       "1                                                 [sooo, sad, i, will, miss, you, here, in, san, diego, !, !, !]   \n",
       "2                                                                              [my, boss, is, bullying, me, ...]   \n",
       "3                                                                         [what, interview, !, leave, me, alone]   \n",
       "4          [sons, of, *, *, *, *, ,, why, couldn, `, t, they, put, them, on, the, releases, we, already, bought]   \n",
       "5  [http, :, //www.dothebouncy.com/smf, -, some, shameless, plugging, for, the, best, rangers, forum, on, earth]   \n",
       "6                                [2am, feedings, for, the, baby, are, fun, when, he, is, all, smiles, and, coos]   \n",
       "7                                                                                                  [soooo, high]   \n",
       "8                                                                                                [both, of, you]   \n",
       "9               [journey, !, ?, wow, ..., u, just, became, cooler, ., hehe, ..., (, is, that, possible, !, ?, )]   \n",
       "\n",
       "                                                                                    no_stops  \n",
       "0                                                                   [`, responded, ,, going]  \n",
       "1                                                     [sooo, sad, miss, san, diego, !, !, !]  \n",
       "2                                                                      [boss, bullying, ...]  \n",
       "3                                                               [interview, !, leave, alone]  \n",
       "4                                   [sons, *, *, *, *, ,, `, put, releases, already, bought]  \n",
       "5  [http, :, //www.dothebouncy.com/smf, -, shameless, plugging, best, rangers, forum, earth]  \n",
       "6                                                   [2am, feedings, baby, fun, smiles, coos]  \n",
       "7                                                                              [soooo, high]  \n",
       "8                                                                                         []  \n",
       "9           [journey, !, ?, wow, ..., u, became, cooler, ., hehe, ..., (, possible, !, ?, )]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## [v3 For Loop - Using continue] Remove Stopwords Function\n",
    "def remove_stopwords(tokens):\n",
    "    no_stops = []\n",
    "    \n",
    "    for token in tokens:\n",
    "        if token in stop_words:\n",
    "            continue\n",
    "            \n",
    "        else:\n",
    "            no_stops.append(token)\n",
    "            \n",
    "    return no_stops\n",
    "\n",
    "df['no_stops'] = df['tokens'].map(remove_stopwords)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b265e55-4bdd-422c-86df-51c096b70988",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a29e8234-98a9-4e5b-8994-71be25afc15d",
   "metadata": {},
   "source": [
    "## Remove Punctuation\n",
    "\n",
    "We can remove punctuation in a similar that we removed stop words.  However, we will get our list of punctuation from the built in Python string library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81cb2857-8b5f-4c61-99f0-3a4151f0c0b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:15:05.519698Z",
     "iopub.status.busy": "2023-12-19T01:15:05.519581Z",
     "iopub.status.idle": "2023-12-19T01:15:05.521765Z",
     "shell.execute_reply": "2023-12-19T01:15:05.521388Z",
     "shell.execute_reply.started": "2023-12-19T01:15:05.519689Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "## Import built-in String Libary\n",
    "from string import punctuation\n",
    "print(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c02a29f-39f3-4671-93f8-0452c223fe61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:15:05.522229Z",
     "iopub.status.busy": "2023-12-19T01:15:05.522126Z",
     "iopub.status.idle": "2023-12-19T01:15:05.582383Z",
     "shell.execute_reply": "2023-12-19T01:15:05.580267Z",
     "shell.execute_reply.started": "2023-12-19T01:15:05.522221Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>length</th>\n",
       "      <th>lower_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>no_stops</th>\n",
       "      <th>no_stops_no_punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>36</td>\n",
       "      <td>i`d have responded, if i were going</td>\n",
       "      <td>[i, `, d, have, responded, ,, if, i, were, going]</td>\n",
       "      <td>[`, responded, ,, going]</td>\n",
       "      <td>[responded, going]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>negative</td>\n",
       "      <td>46</td>\n",
       "      <td>sooo sad i will miss you here in san diego!!!</td>\n",
       "      <td>[sooo, sad, i, will, miss, you, here, in, san, diego, !, !, !]</td>\n",
       "      <td>[sooo, sad, miss, san, diego, !, !, !]</td>\n",
       "      <td>[sooo, sad, miss, san, diego]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>negative</td>\n",
       "      <td>25</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>[my, boss, is, bullying, me, ...]</td>\n",
       "      <td>[boss, bullying, ...]</td>\n",
       "      <td>[boss, bullying, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>31</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>[what, interview, !, leave, me, alone]</td>\n",
       "      <td>[interview, !, leave, alone]</td>\n",
       "      <td>[interview, leave, alone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on the releases we already bought</td>\n",
       "      <td>negative</td>\n",
       "      <td>75</td>\n",
       "      <td>sons of ****, why couldn`t they put them on the releases we already bought</td>\n",
       "      <td>[sons, of, *, *, *, *, ,, why, couldn, `, t, they, put, them, on, the, releases, we, already, bought]</td>\n",
       "      <td>[sons, *, *, *, *, ,, `, put, releases, already, bought]</td>\n",
       "      <td>[sons, put, releases, already, bought]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameless plugging for the best Rangers forum on earth</td>\n",
       "      <td>neutral</td>\n",
       "      <td>92</td>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameless plugging for the best rangers forum on earth</td>\n",
       "      <td>[http, :, //www.dothebouncy.com/smf, -, some, shameless, plugging, for, the, best, rangers, forum, on, earth]</td>\n",
       "      <td>[http, :, //www.dothebouncy.com/smf, -, shameless, plugging, best, rangers, forum, earth]</td>\n",
       "      <td>[http, //www.dothebouncy.com/smf, shameless, plugging, best, rangers, forum, earth]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2am feedings for the baby are fun when he is all smiles and coos</td>\n",
       "      <td>positive</td>\n",
       "      <td>64</td>\n",
       "      <td>2am feedings for the baby are fun when he is all smiles and coos</td>\n",
       "      <td>[2am, feedings, for, the, baby, are, fun, when, he, is, all, smiles, and, coos]</td>\n",
       "      <td>[2am, feedings, baby, fun, smiles, coos]</td>\n",
       "      <td>[2am, feedings, baby, fun, smiles, coos]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Soooo high</td>\n",
       "      <td>neutral</td>\n",
       "      <td>10</td>\n",
       "      <td>soooo high</td>\n",
       "      <td>[soooo, high]</td>\n",
       "      <td>[soooo, high]</td>\n",
       "      <td>[soooo, high]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Both of you</td>\n",
       "      <td>neutral</td>\n",
       "      <td>12</td>\n",
       "      <td>both of you</td>\n",
       "      <td>[both, of, you]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Journey!? Wow... u just became cooler.  hehe... (is that possible!?)</td>\n",
       "      <td>positive</td>\n",
       "      <td>69</td>\n",
       "      <td>journey!? wow... u just became cooler.  hehe... (is that possible!?)</td>\n",
       "      <td>[journey, !, ?, wow, ..., u, just, became, cooler, ., hehe, ..., (, is, that, possible, !, ?, )]</td>\n",
       "      <td>[journey, !, ?, wow, ..., u, became, cooler, ., hehe, ..., (, possible, !, ?, )]</td>\n",
       "      <td>[journey, wow, ..., u, became, cooler, hehe, ..., possible]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                           text  \\\n",
       "0                                                           I`d have responded, if I were going   \n",
       "1                                                 Sooo SAD I will miss you here in San Diego!!!   \n",
       "2                                                                     my boss is bullying me...   \n",
       "3                                                                what interview! leave me alone   \n",
       "4                    Sons of ****, why couldn`t they put them on the releases we already bought   \n",
       "5  http://www.dothebouncy.com/smf - some shameless plugging for the best Rangers forum on earth   \n",
       "6                              2am feedings for the baby are fun when he is all smiles and coos   \n",
       "7                                                                                    Soooo high   \n",
       "8                                                                                   Both of you   \n",
       "9                          Journey!? Wow... u just became cooler.  hehe... (is that possible!?)   \n",
       "\n",
       "  sentiment  length  \\\n",
       "0   neutral      36   \n",
       "1  negative      46   \n",
       "2  negative      25   \n",
       "3  negative      31   \n",
       "4  negative      75   \n",
       "5   neutral      92   \n",
       "6  positive      64   \n",
       "7   neutral      10   \n",
       "8   neutral      12   \n",
       "9  positive      69   \n",
       "\n",
       "                                                                                     lower_text  \\\n",
       "0                                                           i`d have responded, if i were going   \n",
       "1                                                 sooo sad i will miss you here in san diego!!!   \n",
       "2                                                                     my boss is bullying me...   \n",
       "3                                                                what interview! leave me alone   \n",
       "4                    sons of ****, why couldn`t they put them on the releases we already bought   \n",
       "5  http://www.dothebouncy.com/smf - some shameless plugging for the best rangers forum on earth   \n",
       "6                              2am feedings for the baby are fun when he is all smiles and coos   \n",
       "7                                                                                    soooo high   \n",
       "8                                                                                   both of you   \n",
       "9                          journey!? wow... u just became cooler.  hehe... (is that possible!?)   \n",
       "\n",
       "                                                                                                          tokens  \\\n",
       "0                                                              [i, `, d, have, responded, ,, if, i, were, going]   \n",
       "1                                                 [sooo, sad, i, will, miss, you, here, in, san, diego, !, !, !]   \n",
       "2                                                                              [my, boss, is, bullying, me, ...]   \n",
       "3                                                                         [what, interview, !, leave, me, alone]   \n",
       "4          [sons, of, *, *, *, *, ,, why, couldn, `, t, they, put, them, on, the, releases, we, already, bought]   \n",
       "5  [http, :, //www.dothebouncy.com/smf, -, some, shameless, plugging, for, the, best, rangers, forum, on, earth]   \n",
       "6                                [2am, feedings, for, the, baby, are, fun, when, he, is, all, smiles, and, coos]   \n",
       "7                                                                                                  [soooo, high]   \n",
       "8                                                                                                [both, of, you]   \n",
       "9               [journey, !, ?, wow, ..., u, just, became, cooler, ., hehe, ..., (, is, that, possible, !, ?, )]   \n",
       "\n",
       "                                                                                    no_stops  \\\n",
       "0                                                                   [`, responded, ,, going]   \n",
       "1                                                     [sooo, sad, miss, san, diego, !, !, !]   \n",
       "2                                                                      [boss, bullying, ...]   \n",
       "3                                                               [interview, !, leave, alone]   \n",
       "4                                   [sons, *, *, *, *, ,, `, put, releases, already, bought]   \n",
       "5  [http, :, //www.dothebouncy.com/smf, -, shameless, plugging, best, rangers, forum, earth]   \n",
       "6                                                   [2am, feedings, baby, fun, smiles, coos]   \n",
       "7                                                                              [soooo, high]   \n",
       "8                                                                                         []   \n",
       "9           [journey, !, ?, wow, ..., u, became, cooler, ., hehe, ..., (, possible, !, ?, )]   \n",
       "\n",
       "                                                                     no_stops_no_punct  \n",
       "0                                                                   [responded, going]  \n",
       "1                                                        [sooo, sad, miss, san, diego]  \n",
       "2                                                                [boss, bullying, ...]  \n",
       "3                                                            [interview, leave, alone]  \n",
       "4                                               [sons, put, releases, already, bought]  \n",
       "5  [http, //www.dothebouncy.com/smf, shameless, plugging, best, rangers, forum, earth]  \n",
       "6                                             [2am, feedings, baby, fun, smiles, coos]  \n",
       "7                                                                        [soooo, high]  \n",
       "8                                                                                   []  \n",
       "9                          [journey, wow, ..., u, became, cooler, hehe, ..., possible]  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## [v1 List Comp] Remove punctuation\n",
    "def remove_punct(tokens):\n",
    "    no_punct = [token for token in tokens if not token in punctuation]\n",
    "    return no_punct\n",
    "\n",
    "df['no_stops_no_punct'] = df['no_stops'].apply(remove_punct)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7219d1d-e855-4d16-bf72-90165e1b3592",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:15:05.583051Z",
     "iopub.status.busy": "2023-12-19T01:15:05.582929Z",
     "iopub.status.idle": "2023-12-19T01:15:05.696352Z",
     "shell.execute_reply": "2023-12-19T01:15:05.695913Z",
     "shell.execute_reply.started": "2023-12-19T01:15:05.583042Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>length</th>\n",
       "      <th>lower_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>no_stops</th>\n",
       "      <th>no_stops_no_punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>36</td>\n",
       "      <td>i`d have responded, if i were going</td>\n",
       "      <td>[i, `, d, have, responded, ,, if, i, were, going]</td>\n",
       "      <td>[`, responded, ,, going]</td>\n",
       "      <td>[responded, going]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>negative</td>\n",
       "      <td>46</td>\n",
       "      <td>sooo sad i will miss you here in san diego!!!</td>\n",
       "      <td>[sooo, sad, i, will, miss, you, here, in, san, diego, !, !, !]</td>\n",
       "      <td>[sooo, sad, miss, san, diego, !, !, !]</td>\n",
       "      <td>[sooo, sad, miss, san, diego]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>negative</td>\n",
       "      <td>25</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>[my, boss, is, bullying, me, ...]</td>\n",
       "      <td>[boss, bullying, ...]</td>\n",
       "      <td>[boss, bullying, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>31</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>[what, interview, !, leave, me, alone]</td>\n",
       "      <td>[interview, !, leave, alone]</td>\n",
       "      <td>[interview, leave, alone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on the releases we already bought</td>\n",
       "      <td>negative</td>\n",
       "      <td>75</td>\n",
       "      <td>sons of ****, why couldn`t they put them on the releases we already bought</td>\n",
       "      <td>[sons, of, *, *, *, *, ,, why, couldn, `, t, they, put, them, on, the, releases, we, already, bought]</td>\n",
       "      <td>[sons, *, *, *, *, ,, `, put, releases, already, bought]</td>\n",
       "      <td>[sons, put, releases, already, bought]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameless plugging for the best Rangers forum on earth</td>\n",
       "      <td>neutral</td>\n",
       "      <td>92</td>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameless plugging for the best rangers forum on earth</td>\n",
       "      <td>[http, :, //www.dothebouncy.com/smf, -, some, shameless, plugging, for, the, best, rangers, forum, on, earth]</td>\n",
       "      <td>[http, :, //www.dothebouncy.com/smf, -, shameless, plugging, best, rangers, forum, earth]</td>\n",
       "      <td>[http, //www.dothebouncy.com/smf, shameless, plugging, best, rangers, forum, earth]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2am feedings for the baby are fun when he is all smiles and coos</td>\n",
       "      <td>positive</td>\n",
       "      <td>64</td>\n",
       "      <td>2am feedings for the baby are fun when he is all smiles and coos</td>\n",
       "      <td>[2am, feedings, for, the, baby, are, fun, when, he, is, all, smiles, and, coos]</td>\n",
       "      <td>[2am, feedings, baby, fun, smiles, coos]</td>\n",
       "      <td>[2am, feedings, baby, fun, smiles, coos]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Soooo high</td>\n",
       "      <td>neutral</td>\n",
       "      <td>10</td>\n",
       "      <td>soooo high</td>\n",
       "      <td>[soooo, high]</td>\n",
       "      <td>[soooo, high]</td>\n",
       "      <td>[soooo, high]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Both of you</td>\n",
       "      <td>neutral</td>\n",
       "      <td>12</td>\n",
       "      <td>both of you</td>\n",
       "      <td>[both, of, you]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Journey!? Wow... u just became cooler.  hehe... (is that possible!?)</td>\n",
       "      <td>positive</td>\n",
       "      <td>69</td>\n",
       "      <td>journey!? wow... u just became cooler.  hehe... (is that possible!?)</td>\n",
       "      <td>[journey, !, ?, wow, ..., u, just, became, cooler, ., hehe, ..., (, is, that, possible, !, ?, )]</td>\n",
       "      <td>[journey, !, ?, wow, ..., u, became, cooler, ., hehe, ..., (, possible, !, ?, )]</td>\n",
       "      <td>[journey, wow, ..., u, became, cooler, hehe, ..., possible]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                           text  \\\n",
       "0                                                           I`d have responded, if I were going   \n",
       "1                                                 Sooo SAD I will miss you here in San Diego!!!   \n",
       "2                                                                     my boss is bullying me...   \n",
       "3                                                                what interview! leave me alone   \n",
       "4                    Sons of ****, why couldn`t they put them on the releases we already bought   \n",
       "5  http://www.dothebouncy.com/smf - some shameless plugging for the best Rangers forum on earth   \n",
       "6                              2am feedings for the baby are fun when he is all smiles and coos   \n",
       "7                                                                                    Soooo high   \n",
       "8                                                                                   Both of you   \n",
       "9                          Journey!? Wow... u just became cooler.  hehe... (is that possible!?)   \n",
       "\n",
       "  sentiment  length  \\\n",
       "0   neutral      36   \n",
       "1  negative      46   \n",
       "2  negative      25   \n",
       "3  negative      31   \n",
       "4  negative      75   \n",
       "5   neutral      92   \n",
       "6  positive      64   \n",
       "7   neutral      10   \n",
       "8   neutral      12   \n",
       "9  positive      69   \n",
       "\n",
       "                                                                                     lower_text  \\\n",
       "0                                                           i`d have responded, if i were going   \n",
       "1                                                 sooo sad i will miss you here in san diego!!!   \n",
       "2                                                                     my boss is bullying me...   \n",
       "3                                                                what interview! leave me alone   \n",
       "4                    sons of ****, why couldn`t they put them on the releases we already bought   \n",
       "5  http://www.dothebouncy.com/smf - some shameless plugging for the best rangers forum on earth   \n",
       "6                              2am feedings for the baby are fun when he is all smiles and coos   \n",
       "7                                                                                    soooo high   \n",
       "8                                                                                   both of you   \n",
       "9                          journey!? wow... u just became cooler.  hehe... (is that possible!?)   \n",
       "\n",
       "                                                                                                          tokens  \\\n",
       "0                                                              [i, `, d, have, responded, ,, if, i, were, going]   \n",
       "1                                                 [sooo, sad, i, will, miss, you, here, in, san, diego, !, !, !]   \n",
       "2                                                                              [my, boss, is, bullying, me, ...]   \n",
       "3                                                                         [what, interview, !, leave, me, alone]   \n",
       "4          [sons, of, *, *, *, *, ,, why, couldn, `, t, they, put, them, on, the, releases, we, already, bought]   \n",
       "5  [http, :, //www.dothebouncy.com/smf, -, some, shameless, plugging, for, the, best, rangers, forum, on, earth]   \n",
       "6                                [2am, feedings, for, the, baby, are, fun, when, he, is, all, smiles, and, coos]   \n",
       "7                                                                                                  [soooo, high]   \n",
       "8                                                                                                [both, of, you]   \n",
       "9               [journey, !, ?, wow, ..., u, just, became, cooler, ., hehe, ..., (, is, that, possible, !, ?, )]   \n",
       "\n",
       "                                                                                    no_stops  \\\n",
       "0                                                                   [`, responded, ,, going]   \n",
       "1                                                     [sooo, sad, miss, san, diego, !, !, !]   \n",
       "2                                                                      [boss, bullying, ...]   \n",
       "3                                                               [interview, !, leave, alone]   \n",
       "4                                   [sons, *, *, *, *, ,, `, put, releases, already, bought]   \n",
       "5  [http, :, //www.dothebouncy.com/smf, -, shameless, plugging, best, rangers, forum, earth]   \n",
       "6                                                   [2am, feedings, baby, fun, smiles, coos]   \n",
       "7                                                                              [soooo, high]   \n",
       "8                                                                                         []   \n",
       "9           [journey, !, ?, wow, ..., u, became, cooler, ., hehe, ..., (, possible, !, ?, )]   \n",
       "\n",
       "                                                                     no_stops_no_punct  \n",
       "0                                                                   [responded, going]  \n",
       "1                                                        [sooo, sad, miss, san, diego]  \n",
       "2                                                                [boss, bullying, ...]  \n",
       "3                                                            [interview, leave, alone]  \n",
       "4                                               [sons, put, releases, already, bought]  \n",
       "5  [http, //www.dothebouncy.com/smf, shameless, plugging, best, rangers, forum, earth]  \n",
       "6                                             [2am, feedings, baby, fun, smiles, coos]  \n",
       "7                                                                        [soooo, high]  \n",
       "8                                                                                   []  \n",
       "9                          [journey, wow, ..., u, became, cooler, hehe, ..., possible]  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [v2 For Loop] Remove punctuation \n",
    "def remove_punct(tokens):\n",
    "    no_punct = []\n",
    "    for token in tokens:\n",
    "        if token not in punctuation:\n",
    "            no_punct.append(token)\n",
    "    return no_punct\n",
    "\n",
    "df['no_stops_no_punct'] = df['no_stops'].apply(remove_punct)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79f929f0-73a2-4360-b801-dcfbc5b38508",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:15:05.696965Z",
     "iopub.status.busy": "2023-12-19T01:15:05.696857Z",
     "iopub.status.idle": "2023-12-19T01:15:05.730104Z",
     "shell.execute_reply": "2023-12-19T01:15:05.729638Z",
     "shell.execute_reply.started": "2023-12-19T01:15:05.696956Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>length</th>\n",
       "      <th>lower_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>no_stops</th>\n",
       "      <th>no_stops_no_punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>36</td>\n",
       "      <td>i`d have responded, if i were going</td>\n",
       "      <td>[i, `, d, have, responded, ,, if, i, were, going]</td>\n",
       "      <td>[`, responded, ,, going]</td>\n",
       "      <td>[responded, going]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>negative</td>\n",
       "      <td>46</td>\n",
       "      <td>sooo sad i will miss you here in san diego!!!</td>\n",
       "      <td>[sooo, sad, i, will, miss, you, here, in, san, diego, !, !, !]</td>\n",
       "      <td>[sooo, sad, miss, san, diego, !, !, !]</td>\n",
       "      <td>[sooo, sad, miss, san, diego]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>negative</td>\n",
       "      <td>25</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>[my, boss, is, bullying, me, ...]</td>\n",
       "      <td>[boss, bullying, ...]</td>\n",
       "      <td>[boss, bullying, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>31</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>[what, interview, !, leave, me, alone]</td>\n",
       "      <td>[interview, !, leave, alone]</td>\n",
       "      <td>[interview, leave, alone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on the releases we already bought</td>\n",
       "      <td>negative</td>\n",
       "      <td>75</td>\n",
       "      <td>sons of ****, why couldn`t they put them on the releases we already bought</td>\n",
       "      <td>[sons, of, *, *, *, *, ,, why, couldn, `, t, they, put, them, on, the, releases, we, already, bought]</td>\n",
       "      <td>[sons, *, *, *, *, ,, `, put, releases, already, bought]</td>\n",
       "      <td>[sons, put, releases, already, bought]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameless plugging for the best Rangers forum on earth</td>\n",
       "      <td>neutral</td>\n",
       "      <td>92</td>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameless plugging for the best rangers forum on earth</td>\n",
       "      <td>[http, :, //www.dothebouncy.com/smf, -, some, shameless, plugging, for, the, best, rangers, forum, on, earth]</td>\n",
       "      <td>[http, :, //www.dothebouncy.com/smf, -, shameless, plugging, best, rangers, forum, earth]</td>\n",
       "      <td>[http, //www.dothebouncy.com/smf, shameless, plugging, best, rangers, forum, earth]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2am feedings for the baby are fun when he is all smiles and coos</td>\n",
       "      <td>positive</td>\n",
       "      <td>64</td>\n",
       "      <td>2am feedings for the baby are fun when he is all smiles and coos</td>\n",
       "      <td>[2am, feedings, for, the, baby, are, fun, when, he, is, all, smiles, and, coos]</td>\n",
       "      <td>[2am, feedings, baby, fun, smiles, coos]</td>\n",
       "      <td>[2am, feedings, baby, fun, smiles, coos]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Soooo high</td>\n",
       "      <td>neutral</td>\n",
       "      <td>10</td>\n",
       "      <td>soooo high</td>\n",
       "      <td>[soooo, high]</td>\n",
       "      <td>[soooo, high]</td>\n",
       "      <td>[soooo, high]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Both of you</td>\n",
       "      <td>neutral</td>\n",
       "      <td>12</td>\n",
       "      <td>both of you</td>\n",
       "      <td>[both, of, you]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Journey!? Wow... u just became cooler.  hehe... (is that possible!?)</td>\n",
       "      <td>positive</td>\n",
       "      <td>69</td>\n",
       "      <td>journey!? wow... u just became cooler.  hehe... (is that possible!?)</td>\n",
       "      <td>[journey, !, ?, wow, ..., u, just, became, cooler, ., hehe, ..., (, is, that, possible, !, ?, )]</td>\n",
       "      <td>[journey, !, ?, wow, ..., u, became, cooler, ., hehe, ..., (, possible, !, ?, )]</td>\n",
       "      <td>[journey, wow, ..., u, became, cooler, hehe, ..., possible]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                           text  \\\n",
       "0                                                           I`d have responded, if I were going   \n",
       "1                                                 Sooo SAD I will miss you here in San Diego!!!   \n",
       "2                                                                     my boss is bullying me...   \n",
       "3                                                                what interview! leave me alone   \n",
       "4                    Sons of ****, why couldn`t they put them on the releases we already bought   \n",
       "5  http://www.dothebouncy.com/smf - some shameless plugging for the best Rangers forum on earth   \n",
       "6                              2am feedings for the baby are fun when he is all smiles and coos   \n",
       "7                                                                                    Soooo high   \n",
       "8                                                                                   Both of you   \n",
       "9                          Journey!? Wow... u just became cooler.  hehe... (is that possible!?)   \n",
       "\n",
       "  sentiment  length  \\\n",
       "0   neutral      36   \n",
       "1  negative      46   \n",
       "2  negative      25   \n",
       "3  negative      31   \n",
       "4  negative      75   \n",
       "5   neutral      92   \n",
       "6  positive      64   \n",
       "7   neutral      10   \n",
       "8   neutral      12   \n",
       "9  positive      69   \n",
       "\n",
       "                                                                                     lower_text  \\\n",
       "0                                                           i`d have responded, if i were going   \n",
       "1                                                 sooo sad i will miss you here in san diego!!!   \n",
       "2                                                                     my boss is bullying me...   \n",
       "3                                                                what interview! leave me alone   \n",
       "4                    sons of ****, why couldn`t they put them on the releases we already bought   \n",
       "5  http://www.dothebouncy.com/smf - some shameless plugging for the best rangers forum on earth   \n",
       "6                              2am feedings for the baby are fun when he is all smiles and coos   \n",
       "7                                                                                    soooo high   \n",
       "8                                                                                   both of you   \n",
       "9                          journey!? wow... u just became cooler.  hehe... (is that possible!?)   \n",
       "\n",
       "                                                                                                          tokens  \\\n",
       "0                                                              [i, `, d, have, responded, ,, if, i, were, going]   \n",
       "1                                                 [sooo, sad, i, will, miss, you, here, in, san, diego, !, !, !]   \n",
       "2                                                                              [my, boss, is, bullying, me, ...]   \n",
       "3                                                                         [what, interview, !, leave, me, alone]   \n",
       "4          [sons, of, *, *, *, *, ,, why, couldn, `, t, they, put, them, on, the, releases, we, already, bought]   \n",
       "5  [http, :, //www.dothebouncy.com/smf, -, some, shameless, plugging, for, the, best, rangers, forum, on, earth]   \n",
       "6                                [2am, feedings, for, the, baby, are, fun, when, he, is, all, smiles, and, coos]   \n",
       "7                                                                                                  [soooo, high]   \n",
       "8                                                                                                [both, of, you]   \n",
       "9               [journey, !, ?, wow, ..., u, just, became, cooler, ., hehe, ..., (, is, that, possible, !, ?, )]   \n",
       "\n",
       "                                                                                    no_stops  \\\n",
       "0                                                                   [`, responded, ,, going]   \n",
       "1                                                     [sooo, sad, miss, san, diego, !, !, !]   \n",
       "2                                                                      [boss, bullying, ...]   \n",
       "3                                                               [interview, !, leave, alone]   \n",
       "4                                   [sons, *, *, *, *, ,, `, put, releases, already, bought]   \n",
       "5  [http, :, //www.dothebouncy.com/smf, -, shameless, plugging, best, rangers, forum, earth]   \n",
       "6                                                   [2am, feedings, baby, fun, smiles, coos]   \n",
       "7                                                                              [soooo, high]   \n",
       "8                                                                                         []   \n",
       "9           [journey, !, ?, wow, ..., u, became, cooler, ., hehe, ..., (, possible, !, ?, )]   \n",
       "\n",
       "                                                                     no_stops_no_punct  \n",
       "0                                                                   [responded, going]  \n",
       "1                                                        [sooo, sad, miss, san, diego]  \n",
       "2                                                                [boss, bullying, ...]  \n",
       "3                                                            [interview, leave, alone]  \n",
       "4                                               [sons, put, releases, already, bought]  \n",
       "5  [http, //www.dothebouncy.com/smf, shameless, plugging, best, rangers, forum, earth]  \n",
       "6                                             [2am, feedings, baby, fun, smiles, coos]  \n",
       "7                                                                        [soooo, high]  \n",
       "8                                                                                   []  \n",
       "9                          [journey, wow, ..., u, became, cooler, hehe, ..., possible]  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [v3 For Loop - Continue] Remove punctuation \n",
    "def remove_punct(tokens):\n",
    "    no_punct = []\n",
    "    for token in tokens:\n",
    "        if token in punctuation:\n",
    "            continue\n",
    "        else:\n",
    "            no_punct.append(token)\n",
    "    return no_punct\n",
    "\n",
    "df['no_stops_no_punct'] = df['no_stops'].apply(remove_punct)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedcc9e8-8ae3-4c5c-b16b-646b65012c36",
   "metadata": {},
   "source": [
    "## Remove URLs\n",
    "\n",
    "We can see that NLTK divided the 'http' and '//www.' portions of the web addresses.  We will need to deal with those separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad6ac7f0-43d8-4aab-9538-b631a4ffdafe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:15:05.735499Z",
     "iopub.status.busy": "2023-12-19T01:15:05.735322Z",
     "iopub.status.idle": "2023-12-19T01:15:05.756247Z",
     "shell.execute_reply": "2023-12-19T01:15:05.755653Z",
     "shell.execute_reply.started": "2023-12-19T01:15:05.735489Z"
    }
   },
   "outputs": [],
   "source": [
    "## [v1 List Comp] Define function to remove URLs\n",
    "def remove_urls(token_list):\n",
    "    no_urls = [token for token in token_list if not 'http' in token and not 'www' in token]\n",
    "    return no_urls\n",
    "\n",
    "## Remove URLs from no_stops_no_punct\n",
    "df['no_stops_no_punct'] = df['no_stops_no_punct'].apply(remove_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f1cdea4-12f4-47d7-9180-76f95dd29bb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:15:05.757121Z",
     "iopub.status.busy": "2023-12-19T01:15:05.756970Z",
     "iopub.status.idle": "2023-12-19T01:15:05.865474Z",
     "shell.execute_reply": "2023-12-19T01:15:05.865024Z",
     "shell.execute_reply.started": "2023-12-19T01:15:05.757110Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>length</th>\n",
       "      <th>lower_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>no_stops</th>\n",
       "      <th>no_stops_no_punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>36</td>\n",
       "      <td>i`d have responded, if i were going</td>\n",
       "      <td>[i, `, d, have, responded, ,, if, i, were, going]</td>\n",
       "      <td>[`, responded, ,, going]</td>\n",
       "      <td>[responded, going]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>negative</td>\n",
       "      <td>46</td>\n",
       "      <td>sooo sad i will miss you here in san diego!!!</td>\n",
       "      <td>[sooo, sad, i, will, miss, you, here, in, san, diego, !, !, !]</td>\n",
       "      <td>[sooo, sad, miss, san, diego, !, !, !]</td>\n",
       "      <td>[sooo, sad, miss, san, diego]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>negative</td>\n",
       "      <td>25</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>[my, boss, is, bullying, me, ...]</td>\n",
       "      <td>[boss, bullying, ...]</td>\n",
       "      <td>[boss, bullying, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>31</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>[what, interview, !, leave, me, alone]</td>\n",
       "      <td>[interview, !, leave, alone]</td>\n",
       "      <td>[interview, leave, alone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on the releases we already bought</td>\n",
       "      <td>negative</td>\n",
       "      <td>75</td>\n",
       "      <td>sons of ****, why couldn`t they put them on the releases we already bought</td>\n",
       "      <td>[sons, of, *, *, *, *, ,, why, couldn, `, t, they, put, them, on, the, releases, we, already, bought]</td>\n",
       "      <td>[sons, *, *, *, *, ,, `, put, releases, already, bought]</td>\n",
       "      <td>[sons, put, releases, already, bought]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>wish we could come see u on Denver  husband lost his job and can`t afford it</td>\n",
       "      <td>negative</td>\n",
       "      <td>77</td>\n",
       "      <td>wish we could come see u on denver  husband lost his job and can`t afford it</td>\n",
       "      <td>[wish, we, could, come, see, u, on, denver, husband, lost, his, job, and, can, `, t, afford, it]</td>\n",
       "      <td>[wish, could, come, see, u, denver, husband, lost, job, `, afford]</td>\n",
       "      <td>[wish, could, come, see, u, denver, husband, lost, job, afford]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>I`ve wondered about rake to.  The client has made it clear .NET only, don`t force devs to learn a new lang  #agile #ccnet</td>\n",
       "      <td>negative</td>\n",
       "      <td>122</td>\n",
       "      <td>i`ve wondered about rake to.  the client has made it clear .net only, don`t force devs to learn a new lang  #agile #ccnet</td>\n",
       "      <td>[i, `, ve, wondered, about, rake, to, ., the, client, has, made, it, clear, .net, only, ,, don, `, t, force, devs, to, learn, a, new, lang, #, agile, #, ccnet]</td>\n",
       "      <td>[`, wondered, rake, ., client, made, clear, .net, ,, `, force, devs, learn, new, lang, #, agile, #, ccnet]</td>\n",
       "      <td>[wondered, rake, client, made, clear, .net, force, devs, learn, new, lang, agile, ccnet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>Yay good for both of you. Enjoy the break - you probably need it after such hectic weekend  Take care hun xxxx</td>\n",
       "      <td>positive</td>\n",
       "      <td>111</td>\n",
       "      <td>yay good for both of you. enjoy the break - you probably need it after such hectic weekend  take care hun xxxx</td>\n",
       "      <td>[yay, good, for, both, of, you, ., enjoy, the, break, -, you, probably, need, it, after, such, hectic, weekend, take, care, hun, xxxx]</td>\n",
       "      <td>[yay, good, ., enjoy, break, -, probably, need, hectic, weekend, take, care, hun, xxxx]</td>\n",
       "      <td>[yay, good, enjoy, break, probably, need, hectic, weekend, take, care, hun, xxxx]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>positive</td>\n",
       "      <td>27</td>\n",
       "      <td>but it was worth it  ****.</td>\n",
       "      <td>[but, it, was, worth, it, *, *, *, *, .]</td>\n",
       "      <td>[worth, *, *, *, *, .]</td>\n",
       "      <td>[worth]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27480</th>\n",
       "      <td>All this flirting going on - The ATG smiles. Yay.  ((hugs))</td>\n",
       "      <td>neutral</td>\n",
       "      <td>62</td>\n",
       "      <td>all this flirting going on - the atg smiles. yay.  ((hugs))</td>\n",
       "      <td>[all, this, flirting, going, on, -, the, atg, smiles, ., yay, ., (, (, hugs, ), )]</td>\n",
       "      <td>[flirting, going, -, atg, smiles, ., yay, ., (, (, hugs, ), )]</td>\n",
       "      <td>[flirting, going, atg, smiles, yay, hugs]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27480 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                             text  \\\n",
       "0                                                                                             I`d have responded, if I were going   \n",
       "1                                                                                   Sooo SAD I will miss you here in San Diego!!!   \n",
       "2                                                                                                       my boss is bullying me...   \n",
       "3                                                                                                  what interview! leave me alone   \n",
       "4                                                      Sons of ****, why couldn`t they put them on the releases we already bought   \n",
       "...                                                                                                                           ...   \n",
       "27476                                                wish we could come see u on Denver  husband lost his job and can`t afford it   \n",
       "27477   I`ve wondered about rake to.  The client has made it clear .NET only, don`t force devs to learn a new lang  #agile #ccnet   \n",
       "27478              Yay good for both of you. Enjoy the break - you probably need it after such hectic weekend  Take care hun xxxx   \n",
       "27479                                                                                                  But it was worth it  ****.   \n",
       "27480                                                                 All this flirting going on - The ATG smiles. Yay.  ((hugs))   \n",
       "\n",
       "      sentiment  length  \\\n",
       "0       neutral      36   \n",
       "1      negative      46   \n",
       "2      negative      25   \n",
       "3      negative      31   \n",
       "4      negative      75   \n",
       "...         ...     ...   \n",
       "27476  negative      77   \n",
       "27477  negative     122   \n",
       "27478  positive     111   \n",
       "27479  positive      27   \n",
       "27480   neutral      62   \n",
       "\n",
       "                                                                                                                       lower_text  \\\n",
       "0                                                                                             i`d have responded, if i were going   \n",
       "1                                                                                   sooo sad i will miss you here in san diego!!!   \n",
       "2                                                                                                       my boss is bullying me...   \n",
       "3                                                                                                  what interview! leave me alone   \n",
       "4                                                      sons of ****, why couldn`t they put them on the releases we already bought   \n",
       "...                                                                                                                           ...   \n",
       "27476                                                wish we could come see u on denver  husband lost his job and can`t afford it   \n",
       "27477   i`ve wondered about rake to.  the client has made it clear .net only, don`t force devs to learn a new lang  #agile #ccnet   \n",
       "27478              yay good for both of you. enjoy the break - you probably need it after such hectic weekend  take care hun xxxx   \n",
       "27479                                                                                                  but it was worth it  ****.   \n",
       "27480                                                                 all this flirting going on - the atg smiles. yay.  ((hugs))   \n",
       "\n",
       "                                                                                                                                                                tokens  \\\n",
       "0                                                                                                                    [i, `, d, have, responded, ,, if, i, were, going]   \n",
       "1                                                                                                       [sooo, sad, i, will, miss, you, here, in, san, diego, !, !, !]   \n",
       "2                                                                                                                                    [my, boss, is, bullying, me, ...]   \n",
       "3                                                                                                                               [what, interview, !, leave, me, alone]   \n",
       "4                                                                [sons, of, *, *, *, *, ,, why, couldn, `, t, they, put, them, on, the, releases, we, already, bought]   \n",
       "...                                                                                                                                                                ...   \n",
       "27476                                                                 [wish, we, could, come, see, u, on, denver, husband, lost, his, job, and, can, `, t, afford, it]   \n",
       "27477  [i, `, ve, wondered, about, rake, to, ., the, client, has, made, it, clear, .net, only, ,, don, `, t, force, devs, to, learn, a, new, lang, #, agile, #, ccnet]   \n",
       "27478                           [yay, good, for, both, of, you, ., enjoy, the, break, -, you, probably, need, it, after, such, hectic, weekend, take, care, hun, xxxx]   \n",
       "27479                                                                                                                         [but, it, was, worth, it, *, *, *, *, .]   \n",
       "27480                                                                               [all, this, flirting, going, on, -, the, atg, smiles, ., yay, ., (, (, hugs, ), )]   \n",
       "\n",
       "                                                                                                         no_stops  \\\n",
       "0                                                                                        [`, responded, ,, going]   \n",
       "1                                                                          [sooo, sad, miss, san, diego, !, !, !]   \n",
       "2                                                                                           [boss, bullying, ...]   \n",
       "3                                                                                    [interview, !, leave, alone]   \n",
       "4                                                        [sons, *, *, *, *, ,, `, put, releases, already, bought]   \n",
       "...                                                                                                           ...   \n",
       "27476                                          [wish, could, come, see, u, denver, husband, lost, job, `, afford]   \n",
       "27477  [`, wondered, rake, ., client, made, clear, .net, ,, `, force, devs, learn, new, lang, #, agile, #, ccnet]   \n",
       "27478                     [yay, good, ., enjoy, break, -, probably, need, hectic, weekend, take, care, hun, xxxx]   \n",
       "27479                                                                                      [worth, *, *, *, *, .]   \n",
       "27480                                              [flirting, going, -, atg, smiles, ., yay, ., (, (, hugs, ), )]   \n",
       "\n",
       "                                                                              no_stops_no_punct  \n",
       "0                                                                            [responded, going]  \n",
       "1                                                                 [sooo, sad, miss, san, diego]  \n",
       "2                                                                         [boss, bullying, ...]  \n",
       "3                                                                     [interview, leave, alone]  \n",
       "4                                                        [sons, put, releases, already, bought]  \n",
       "...                                                                                         ...  \n",
       "27476                           [wish, could, come, see, u, denver, husband, lost, job, afford]  \n",
       "27477  [wondered, rake, client, made, clear, .net, force, devs, learn, new, lang, agile, ccnet]  \n",
       "27478         [yay, good, enjoy, break, probably, need, hectic, weekend, take, care, hun, xxxx]  \n",
       "27479                                                                                   [worth]  \n",
       "27480                                                 [flirting, going, atg, smiles, yay, hugs]  \n",
       "\n",
       "[27480 rows x 7 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## [v2 For Loop] Define function to remove URLs\n",
    "def remove_urls(token_list):\n",
    "    no_urls = []\n",
    "    for token in token_list:\n",
    "        if ('http' not in token) & ('www' not in token):\n",
    "            no_urls.append(token)\n",
    "    return no_urls\n",
    "\n",
    "## Remove URLs from no_stops_no_punct\n",
    "df['no_stops_no_punct'] = df['no_stops_no_punct'].apply(remove_urls)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9707d947-b458-4de6-987a-7deb28c63b01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:15:05.866210Z",
     "iopub.status.busy": "2023-12-19T01:15:05.866101Z",
     "iopub.status.idle": "2023-12-19T01:15:05.890588Z",
     "shell.execute_reply": "2023-12-19T01:15:05.890189Z",
     "shell.execute_reply.started": "2023-12-19T01:15:05.866201Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>length</th>\n",
       "      <th>lower_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>no_stops</th>\n",
       "      <th>no_stops_no_punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>36</td>\n",
       "      <td>i`d have responded, if i were going</td>\n",
       "      <td>[i, `, d, have, responded, ,, if, i, were, going]</td>\n",
       "      <td>[`, responded, ,, going]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>negative</td>\n",
       "      <td>46</td>\n",
       "      <td>sooo sad i will miss you here in san diego!!!</td>\n",
       "      <td>[sooo, sad, i, will, miss, you, here, in, san, diego, !, !, !]</td>\n",
       "      <td>[sooo, sad, miss, san, diego, !, !, !]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>negative</td>\n",
       "      <td>25</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>[my, boss, is, bullying, me, ...]</td>\n",
       "      <td>[boss, bullying, ...]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>31</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>[what, interview, !, leave, me, alone]</td>\n",
       "      <td>[interview, !, leave, alone]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on the releases we already bought</td>\n",
       "      <td>negative</td>\n",
       "      <td>75</td>\n",
       "      <td>sons of ****, why couldn`t they put them on the releases we already bought</td>\n",
       "      <td>[sons, of, *, *, *, *, ,, why, couldn, `, t, they, put, them, on, the, releases, we, already, bought]</td>\n",
       "      <td>[sons, *, *, *, *, ,, `, put, releases, already, bought]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>wish we could come see u on Denver  husband lost his job and can`t afford it</td>\n",
       "      <td>negative</td>\n",
       "      <td>77</td>\n",
       "      <td>wish we could come see u on denver  husband lost his job and can`t afford it</td>\n",
       "      <td>[wish, we, could, come, see, u, on, denver, husband, lost, his, job, and, can, `, t, afford, it]</td>\n",
       "      <td>[wish, could, come, see, u, denver, husband, lost, job, `, afford]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>I`ve wondered about rake to.  The client has made it clear .NET only, don`t force devs to learn a new lang  #agile #ccnet</td>\n",
       "      <td>negative</td>\n",
       "      <td>122</td>\n",
       "      <td>i`ve wondered about rake to.  the client has made it clear .net only, don`t force devs to learn a new lang  #agile #ccnet</td>\n",
       "      <td>[i, `, ve, wondered, about, rake, to, ., the, client, has, made, it, clear, .net, only, ,, don, `, t, force, devs, to, learn, a, new, lang, #, agile, #, ccnet]</td>\n",
       "      <td>[`, wondered, rake, ., client, made, clear, .net, ,, `, force, devs, learn, new, lang, #, agile, #, ccnet]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>Yay good for both of you. Enjoy the break - you probably need it after such hectic weekend  Take care hun xxxx</td>\n",
       "      <td>positive</td>\n",
       "      <td>111</td>\n",
       "      <td>yay good for both of you. enjoy the break - you probably need it after such hectic weekend  take care hun xxxx</td>\n",
       "      <td>[yay, good, for, both, of, you, ., enjoy, the, break, -, you, probably, need, it, after, such, hectic, weekend, take, care, hun, xxxx]</td>\n",
       "      <td>[yay, good, ., enjoy, break, -, probably, need, hectic, weekend, take, care, hun, xxxx]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>positive</td>\n",
       "      <td>27</td>\n",
       "      <td>but it was worth it  ****.</td>\n",
       "      <td>[but, it, was, worth, it, *, *, *, *, .]</td>\n",
       "      <td>[worth, *, *, *, *, .]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27480</th>\n",
       "      <td>All this flirting going on - The ATG smiles. Yay.  ((hugs))</td>\n",
       "      <td>neutral</td>\n",
       "      <td>62</td>\n",
       "      <td>all this flirting going on - the atg smiles. yay.  ((hugs))</td>\n",
       "      <td>[all, this, flirting, going, on, -, the, atg, smiles, ., yay, ., (, (, hugs, ), )]</td>\n",
       "      <td>[flirting, going, -, atg, smiles, ., yay, ., (, (, hugs, ), )]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27480 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                             text  \\\n",
       "0                                                                                             I`d have responded, if I were going   \n",
       "1                                                                                   Sooo SAD I will miss you here in San Diego!!!   \n",
       "2                                                                                                       my boss is bullying me...   \n",
       "3                                                                                                  what interview! leave me alone   \n",
       "4                                                      Sons of ****, why couldn`t they put them on the releases we already bought   \n",
       "...                                                                                                                           ...   \n",
       "27476                                                wish we could come see u on Denver  husband lost his job and can`t afford it   \n",
       "27477   I`ve wondered about rake to.  The client has made it clear .NET only, don`t force devs to learn a new lang  #agile #ccnet   \n",
       "27478              Yay good for both of you. Enjoy the break - you probably need it after such hectic weekend  Take care hun xxxx   \n",
       "27479                                                                                                  But it was worth it  ****.   \n",
       "27480                                                                 All this flirting going on - The ATG smiles. Yay.  ((hugs))   \n",
       "\n",
       "      sentiment  length  \\\n",
       "0       neutral      36   \n",
       "1      negative      46   \n",
       "2      negative      25   \n",
       "3      negative      31   \n",
       "4      negative      75   \n",
       "...         ...     ...   \n",
       "27476  negative      77   \n",
       "27477  negative     122   \n",
       "27478  positive     111   \n",
       "27479  positive      27   \n",
       "27480   neutral      62   \n",
       "\n",
       "                                                                                                                       lower_text  \\\n",
       "0                                                                                             i`d have responded, if i were going   \n",
       "1                                                                                   sooo sad i will miss you here in san diego!!!   \n",
       "2                                                                                                       my boss is bullying me...   \n",
       "3                                                                                                  what interview! leave me alone   \n",
       "4                                                      sons of ****, why couldn`t they put them on the releases we already bought   \n",
       "...                                                                                                                           ...   \n",
       "27476                                                wish we could come see u on denver  husband lost his job and can`t afford it   \n",
       "27477   i`ve wondered about rake to.  the client has made it clear .net only, don`t force devs to learn a new lang  #agile #ccnet   \n",
       "27478              yay good for both of you. enjoy the break - you probably need it after such hectic weekend  take care hun xxxx   \n",
       "27479                                                                                                  but it was worth it  ****.   \n",
       "27480                                                                 all this flirting going on - the atg smiles. yay.  ((hugs))   \n",
       "\n",
       "                                                                                                                                                                tokens  \\\n",
       "0                                                                                                                    [i, `, d, have, responded, ,, if, i, were, going]   \n",
       "1                                                                                                       [sooo, sad, i, will, miss, you, here, in, san, diego, !, !, !]   \n",
       "2                                                                                                                                    [my, boss, is, bullying, me, ...]   \n",
       "3                                                                                                                               [what, interview, !, leave, me, alone]   \n",
       "4                                                                [sons, of, *, *, *, *, ,, why, couldn, `, t, they, put, them, on, the, releases, we, already, bought]   \n",
       "...                                                                                                                                                                ...   \n",
       "27476                                                                 [wish, we, could, come, see, u, on, denver, husband, lost, his, job, and, can, `, t, afford, it]   \n",
       "27477  [i, `, ve, wondered, about, rake, to, ., the, client, has, made, it, clear, .net, only, ,, don, `, t, force, devs, to, learn, a, new, lang, #, agile, #, ccnet]   \n",
       "27478                           [yay, good, for, both, of, you, ., enjoy, the, break, -, you, probably, need, it, after, such, hectic, weekend, take, care, hun, xxxx]   \n",
       "27479                                                                                                                         [but, it, was, worth, it, *, *, *, *, .]   \n",
       "27480                                                                               [all, this, flirting, going, on, -, the, atg, smiles, ., yay, ., (, (, hugs, ), )]   \n",
       "\n",
       "                                                                                                         no_stops  \\\n",
       "0                                                                                        [`, responded, ,, going]   \n",
       "1                                                                          [sooo, sad, miss, san, diego, !, !, !]   \n",
       "2                                                                                           [boss, bullying, ...]   \n",
       "3                                                                                    [interview, !, leave, alone]   \n",
       "4                                                        [sons, *, *, *, *, ,, `, put, releases, already, bought]   \n",
       "...                                                                                                           ...   \n",
       "27476                                          [wish, could, come, see, u, denver, husband, lost, job, `, afford]   \n",
       "27477  [`, wondered, rake, ., client, made, clear, .net, ,, `, force, devs, learn, new, lang, #, agile, #, ccnet]   \n",
       "27478                     [yay, good, ., enjoy, break, -, probably, need, hectic, weekend, take, care, hun, xxxx]   \n",
       "27479                                                                                      [worth, *, *, *, *, .]   \n",
       "27480                                              [flirting, going, -, atg, smiles, ., yay, ., (, (, hugs, ), )]   \n",
       "\n",
       "      no_stops_no_punct  \n",
       "0                    []  \n",
       "1                    []  \n",
       "2                    []  \n",
       "3                    []  \n",
       "4                    []  \n",
       "...                 ...  \n",
       "27476                []  \n",
       "27477                []  \n",
       "27478                []  \n",
       "27479                []  \n",
       "27480                []  \n",
       "\n",
       "[27480 rows x 7 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## [v3 For Loop - Continue] Define function to remove URLs\n",
    "def remove_urls(token_list):\n",
    "    no_urls = []\n",
    "    for token in token_list:\n",
    "        if ('http' in token) | ('www' not in token):\n",
    "            continue\n",
    "        no_urls.append(token)\n",
    "    return no_urls\n",
    "\n",
    "## Remove URLs from no_stops_no_punct\n",
    "df['no_stops_no_punct'] = df['no_stops_no_punct'].apply(remove_urls)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cfa87e1a-9717-4e1f-881c-f885d3f0bcf9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:15:05.891450Z",
     "iopub.status.busy": "2023-12-19T01:15:05.891259Z",
     "iopub.status.idle": "2023-12-19T01:15:05.900412Z",
     "shell.execute_reply": "2023-12-19T01:15:05.900005Z",
     "shell.execute_reply.started": "2023-12-19T01:15:05.891437Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>length</th>\n",
       "      <th>lower_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>no_stops</th>\n",
       "      <th>no_stops_no_punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>36</td>\n",
       "      <td>i`d have responded, if i were going</td>\n",
       "      <td>[i, `, d, have, responded, ,, if, i, were, going]</td>\n",
       "      <td>[`, responded, ,, going]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>negative</td>\n",
       "      <td>46</td>\n",
       "      <td>sooo sad i will miss you here in san diego!!!</td>\n",
       "      <td>[sooo, sad, i, will, miss, you, here, in, san, diego, !, !, !]</td>\n",
       "      <td>[sooo, sad, miss, san, diego, !, !, !]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>negative</td>\n",
       "      <td>25</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>[my, boss, is, bullying, me, ...]</td>\n",
       "      <td>[boss, bullying, ...]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>31</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>[what, interview, !, leave, me, alone]</td>\n",
       "      <td>[interview, !, leave, alone]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on the releases we already bought</td>\n",
       "      <td>negative</td>\n",
       "      <td>75</td>\n",
       "      <td>sons of ****, why couldn`t they put them on the releases we already bought</td>\n",
       "      <td>[sons, of, *, *, *, *, ,, why, couldn, `, t, they, put, them, on, the, releases, we, already, bought]</td>\n",
       "      <td>[sons, *, *, *, *, ,, `, put, releases, already, bought]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameless plugging for the best Rangers forum on earth</td>\n",
       "      <td>neutral</td>\n",
       "      <td>92</td>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameless plugging for the best rangers forum on earth</td>\n",
       "      <td>[http, :, //www.dothebouncy.com/smf, -, some, shameless, plugging, for, the, best, rangers, forum, on, earth]</td>\n",
       "      <td>[http, :, //www.dothebouncy.com/smf, -, shameless, plugging, best, rangers, forum, earth]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2am feedings for the baby are fun when he is all smiles and coos</td>\n",
       "      <td>positive</td>\n",
       "      <td>64</td>\n",
       "      <td>2am feedings for the baby are fun when he is all smiles and coos</td>\n",
       "      <td>[2am, feedings, for, the, baby, are, fun, when, he, is, all, smiles, and, coos]</td>\n",
       "      <td>[2am, feedings, baby, fun, smiles, coos]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Soooo high</td>\n",
       "      <td>neutral</td>\n",
       "      <td>10</td>\n",
       "      <td>soooo high</td>\n",
       "      <td>[soooo, high]</td>\n",
       "      <td>[soooo, high]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Both of you</td>\n",
       "      <td>neutral</td>\n",
       "      <td>12</td>\n",
       "      <td>both of you</td>\n",
       "      <td>[both, of, you]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Journey!? Wow... u just became cooler.  hehe... (is that possible!?)</td>\n",
       "      <td>positive</td>\n",
       "      <td>69</td>\n",
       "      <td>journey!? wow... u just became cooler.  hehe... (is that possible!?)</td>\n",
       "      <td>[journey, !, ?, wow, ..., u, just, became, cooler, ., hehe, ..., (, is, that, possible, !, ?, )]</td>\n",
       "      <td>[journey, !, ?, wow, ..., u, became, cooler, ., hehe, ..., (, possible, !, ?, )]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                           text  \\\n",
       "0                                                           I`d have responded, if I were going   \n",
       "1                                                 Sooo SAD I will miss you here in San Diego!!!   \n",
       "2                                                                     my boss is bullying me...   \n",
       "3                                                                what interview! leave me alone   \n",
       "4                    Sons of ****, why couldn`t they put them on the releases we already bought   \n",
       "5  http://www.dothebouncy.com/smf - some shameless plugging for the best Rangers forum on earth   \n",
       "6                              2am feedings for the baby are fun when he is all smiles and coos   \n",
       "7                                                                                    Soooo high   \n",
       "8                                                                                   Both of you   \n",
       "9                          Journey!? Wow... u just became cooler.  hehe... (is that possible!?)   \n",
       "\n",
       "  sentiment  length  \\\n",
       "0   neutral      36   \n",
       "1  negative      46   \n",
       "2  negative      25   \n",
       "3  negative      31   \n",
       "4  negative      75   \n",
       "5   neutral      92   \n",
       "6  positive      64   \n",
       "7   neutral      10   \n",
       "8   neutral      12   \n",
       "9  positive      69   \n",
       "\n",
       "                                                                                     lower_text  \\\n",
       "0                                                           i`d have responded, if i were going   \n",
       "1                                                 sooo sad i will miss you here in san diego!!!   \n",
       "2                                                                     my boss is bullying me...   \n",
       "3                                                                what interview! leave me alone   \n",
       "4                    sons of ****, why couldn`t they put them on the releases we already bought   \n",
       "5  http://www.dothebouncy.com/smf - some shameless plugging for the best rangers forum on earth   \n",
       "6                              2am feedings for the baby are fun when he is all smiles and coos   \n",
       "7                                                                                    soooo high   \n",
       "8                                                                                   both of you   \n",
       "9                          journey!? wow... u just became cooler.  hehe... (is that possible!?)   \n",
       "\n",
       "                                                                                                          tokens  \\\n",
       "0                                                              [i, `, d, have, responded, ,, if, i, were, going]   \n",
       "1                                                 [sooo, sad, i, will, miss, you, here, in, san, diego, !, !, !]   \n",
       "2                                                                              [my, boss, is, bullying, me, ...]   \n",
       "3                                                                         [what, interview, !, leave, me, alone]   \n",
       "4          [sons, of, *, *, *, *, ,, why, couldn, `, t, they, put, them, on, the, releases, we, already, bought]   \n",
       "5  [http, :, //www.dothebouncy.com/smf, -, some, shameless, plugging, for, the, best, rangers, forum, on, earth]   \n",
       "6                                [2am, feedings, for, the, baby, are, fun, when, he, is, all, smiles, and, coos]   \n",
       "7                                                                                                  [soooo, high]   \n",
       "8                                                                                                [both, of, you]   \n",
       "9               [journey, !, ?, wow, ..., u, just, became, cooler, ., hehe, ..., (, is, that, possible, !, ?, )]   \n",
       "\n",
       "                                                                                    no_stops  \\\n",
       "0                                                                   [`, responded, ,, going]   \n",
       "1                                                     [sooo, sad, miss, san, diego, !, !, !]   \n",
       "2                                                                      [boss, bullying, ...]   \n",
       "3                                                               [interview, !, leave, alone]   \n",
       "4                                   [sons, *, *, *, *, ,, `, put, releases, already, bought]   \n",
       "5  [http, :, //www.dothebouncy.com/smf, -, shameless, plugging, best, rangers, forum, earth]   \n",
       "6                                                   [2am, feedings, baby, fun, smiles, coos]   \n",
       "7                                                                              [soooo, high]   \n",
       "8                                                                                         []   \n",
       "9           [journey, !, ?, wow, ..., u, became, cooler, ., hehe, ..., (, possible, !, ?, )]   \n",
       "\n",
       "  no_stops_no_punct  \n",
       "0                []  \n",
       "1                []  \n",
       "2                []  \n",
       "3                []  \n",
       "4                []  \n",
       "5                []  \n",
       "6                []  \n",
       "7                []  \n",
       "8                []  \n",
       "9                []  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beac0458-1764-4f82-ba99-0dd7ee47a16e",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Note how many fewer tokens we have in our `no_stops_no_punct` tokens than in our original.  However, some information was lost, but a lot was also retained.  \n",
    "\n",
    "Normalization is a huge part of the NLP process and is always a balance between reducing the size of our vocabulary and therefor simplifying our models, and retaining enough information for the model to extract some meaningful patterns in the texts.  \n",
    "\n",
    "There are a lot of choices here to make."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ed88e6-d9b1-4a54-943c-76d26209f01b",
   "metadata": {},
   "source": [
    "# Normalizing Text with spaCy\n",
    "\n",
    "The spaCy Python package provides text processing pipelines that can do many of these operations, plus much more complicated processing, very fast and in many fewer steps.  For this reason it is a very popular tool.  \n",
    "\n",
    "It utilizes pretrained language models that can recognize things like parts of speech and named entities (people, specific places, currency, etc.)\n",
    "\n",
    "spaCy was not included in your original dojo_env, so you will need to install if if you have not already.\n",
    "\n",
    "We will also download the pretrained english language model trained on millions of web documents.  We will use the small sized one for efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "407dbf39-b284-4655-bc4d-f93d70cf9434",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:15:05.901104Z",
     "iopub.status.busy": "2023-12-19T01:15:05.900931Z",
     "iopub.status.idle": "2023-12-19T01:15:05.903670Z",
     "shell.execute_reply": "2023-12-19T01:15:05.903363Z",
     "shell.execute_reply.started": "2023-12-19T01:15:05.901090Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Install spacy if necessary\n",
    "# (best if run in terminal without the \"%\" first character)\n",
    "# %conda install -c conda-forge spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f98c56be-0fc1-4a93-b712-4d65e9b082cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:15:05.904386Z",
     "iopub.status.busy": "2023-12-19T01:15:05.904267Z",
     "iopub.status.idle": "2023-12-19T01:15:10.904557Z",
     "shell.execute_reply": "2023-12-19T01:15:10.904240Z",
     "shell.execute_reply.started": "2023-12-19T01:15:05.904377Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "## Download the English small-sized model trained on web documents if necessary\n",
    "# spacy.cli.download('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4dd253",
   "metadata": {},
   "source": [
    "## The spaCy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "416eaea3-add2-481f-b77e-79c67901f2ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:15:10.905280Z",
     "iopub.status.busy": "2023-12-19T01:15:10.905094Z",
     "iopub.status.idle": "2023-12-19T01:15:11.280568Z",
     "shell.execute_reply": "2023-12-19T01:15:11.280214Z",
     "shell.execute_reply.started": "2023-12-19T01:15:10.905271Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load the model.  Disable Named Entity Recognizer (too slow)\n",
    "nlp_model = spacy.load('en_core_web_sm', disable='ner')\n",
    "nlp_model.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1d4eaf",
   "metadata": {},
   "source": [
    "We have our model, and we can apply it like a function.  It expects a string of text as the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fefbc520",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:15:11.281538Z",
     "iopub.status.busy": "2023-12-19T01:15:11.281248Z",
     "iopub.status.idle": "2023-12-19T01:15:11.288552Z",
     "shell.execute_reply": "2023-12-19T01:15:11.288107Z",
     "shell.execute_reply.started": "2023-12-19T01:15:11.281526Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "http://www.dothebouncy.com/smf - some shameless plugging for the best Rangers forum on earth"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Process a document with the model\n",
    "doc = nlp_model(df['text'][5])\n",
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0acc0c5",
   "metadata": {},
   "source": [
    "The document is a collection of tokens we can iterate over"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45a2269",
   "metadata": {},
   "source": [
    "## Documents and Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1413b79d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:15:11.289344Z",
     "iopub.status.busy": "2023-12-19T01:15:11.289239Z",
     "iopub.status.idle": "2023-12-19T01:15:11.292302Z",
     "shell.execute_reply": "2023-12-19T01:15:11.291850Z",
     "shell.execute_reply.started": "2023-12-19T01:15:11.289335Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[http://www.dothebouncy.com/smf,\n",
       " -,\n",
       " some,\n",
       " shameless,\n",
       " plugging,\n",
       " for,\n",
       " the,\n",
       " best,\n",
       " Rangers,\n",
       " forum,\n",
       " on,\n",
       " earth]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Display the tokens in the document\n",
    "[token for token in doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6c916a",
   "metadata": {},
   "source": [
    "Each token is much more than a string.  It"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "33e23605",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:15:11.292991Z",
     "iopub.status.busy": "2023-12-19T01:15:11.292866Z",
     "iopub.status.idle": "2023-12-19T01:15:11.296634Z",
     "shell.execute_reply": "2023-12-19T01:15:11.295935Z",
     "shell.execute_reply.started": "2023-12-19T01:15:11.292982Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "earth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "spacy.tokens.token.Token"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Isolate the last token in the document\n",
    "word = doc[-1]\n",
    "\n",
    "## Display the text and type of the token\n",
    "print(word)\n",
    "type(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dfe86b",
   "metadata": {},
   "source": [
    "Each has many attributes that we can take advantage of, such as the lemma form and whether it is punctuation or space, and whether it is a stop word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f066c437",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:15:11.298097Z",
     "iopub.status.busy": "2023-12-19T01:15:11.297973Z",
     "iopub.status.idle": "2023-12-19T01:15:11.301339Z",
     "shell.execute_reply": "2023-12-19T01:15:11.300615Z",
     "shell.execute_reply.started": "2023-12-19T01:15:11.298088Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'earth'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Display the lemmatized form of the token\n",
    "word.lemma_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c1885db0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:15:11.302643Z",
     "iopub.status.busy": "2023-12-19T01:15:11.302483Z",
     "iopub.status.idle": "2023-12-19T01:15:11.305462Z",
     "shell.execute_reply": "2023-12-19T01:15:11.305134Z",
     "shell.execute_reply.started": "2023-12-19T01:15:11.302631Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check whether the token is punctuation\n",
    "word.is_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "917804bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:15:11.306167Z",
     "iopub.status.busy": "2023-12-19T01:15:11.306067Z",
     "iopub.status.idle": "2023-12-19T01:15:11.308567Z",
     "shell.execute_reply": "2023-12-19T01:15:11.308273Z",
     "shell.execute_reply.started": "2023-12-19T01:15:11.306151Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check whether the token is a space\n",
    "word.is_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc38694",
   "metadata": {},
   "source": [
    "Spacy can even determine the part of speech that the token is!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f2b0faf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:15:11.309333Z",
     "iopub.status.busy": "2023-12-19T01:15:11.309198Z",
     "iopub.status.idle": "2023-12-19T01:15:11.316155Z",
     "shell.execute_reply": "2023-12-19T01:15:11.315663Z",
     "shell.execute_reply.started": "2023-12-19T01:15:11.309325Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NOUN'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check the part of speech of the token\n",
    "word.pos_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8c001602",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:15:11.316819Z",
     "iopub.status.busy": "2023-12-19T01:15:11.316732Z",
     "iopub.status.idle": "2023-12-19T01:15:11.320208Z",
     "shell.execute_reply": "2023-12-19T01:15:11.319851Z",
     "shell.execute_reply.started": "2023-12-19T01:15:11.316810Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PROPN',\n",
       " 'PUNCT',\n",
       " 'DET',\n",
       " 'ADJ',\n",
       " 'VERB',\n",
       " 'ADP',\n",
       " 'DET',\n",
       " 'ADJ',\n",
       " 'PROPN',\n",
       " 'NOUN',\n",
       " 'ADP',\n",
       " 'NOUN']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token.pos_ for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b3ac61bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:15:11.321397Z",
     "iopub.status.busy": "2023-12-19T01:15:11.321219Z",
     "iopub.status.idle": "2023-12-19T01:15:11.323957Z",
     "shell.execute_reply": "2023-12-19T01:15:11.323607Z",
     "shell.execute_reply.started": "2023-12-19T01:15:11.321369Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.dothebouncy.com/smf',\n",
       " '-',\n",
       " 'some',\n",
       " 'shameless',\n",
       " 'plug',\n",
       " 'for',\n",
       " 'the',\n",
       " 'good',\n",
       " 'Rangers',\n",
       " 'forum',\n",
       " 'on',\n",
       " 'earth']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## [v1: List Comp] Make a list of the lemmas for each token in the document\n",
    "[token.lemma_ for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6c12187c-dfe5-477b-950c-dcb5ad89683c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:15:11.324641Z",
     "iopub.status.busy": "2023-12-19T01:15:11.324476Z",
     "iopub.status.idle": "2023-12-19T01:15:11.328488Z",
     "shell.execute_reply": "2023-12-19T01:15:11.327907Z",
     "shell.execute_reply.started": "2023-12-19T01:15:11.324630Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.dothebouncy.com/smf',\n",
       " '-',\n",
       " 'some',\n",
       " 'shameless',\n",
       " 'plug',\n",
       " 'for',\n",
       " 'the',\n",
       " 'good',\n",
       " 'Rangers',\n",
       " 'forum',\n",
       " 'on',\n",
       " 'earth']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## [v2: For Loop] Make a list of the lemmas for each token in the document- '\n",
    "lemmas_list = []\n",
    "for token in doc:\n",
    "    lemmas_list.append( token.lemma_)\n",
    "lemmas_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5d9cca",
   "metadata": {},
   "source": [
    "Notice that the spaCy lemmatization does not automatically lower the casing of words when lemmatizing.  Let's go ahead and make sure they are all lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e550297a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:15:11.329220Z",
     "iopub.status.busy": "2023-12-19T01:15:11.329074Z",
     "iopub.status.idle": "2023-12-19T01:15:11.333333Z",
     "shell.execute_reply": "2023-12-19T01:15:11.332630Z",
     "shell.execute_reply.started": "2023-12-19T01:15:11.329196Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.dothebouncy.com/smf',\n",
       " 'some',\n",
       " 'shameless',\n",
       " 'plug',\n",
       " 'for',\n",
       " 'the',\n",
       " 'good',\n",
       " 'rangers',\n",
       " 'forum',\n",
       " 'on',\n",
       " 'earth']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## [v1 List Comp] Make a list of only the tokens in the document that are not punctuation or spaces\n",
    "## Lower the casing as well\n",
    "[token.lemma_.lower() for token in doc if not token.is_punct and not token.is_space]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0e2fa17e-5f4c-4f8d-9c32-092be7049e2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:15:11.334384Z",
     "iopub.status.busy": "2023-12-19T01:15:11.334196Z",
     "iopub.status.idle": "2023-12-19T01:15:11.338247Z",
     "shell.execute_reply": "2023-12-19T01:15:11.337835Z",
     "shell.execute_reply.started": "2023-12-19T01:15:11.334372Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.dothebouncy.com/smf',\n",
       " 'some',\n",
       " 'shameless',\n",
       " 'plug',\n",
       " 'for',\n",
       " 'the',\n",
       " 'good',\n",
       " 'rangers',\n",
       " 'forum',\n",
       " 'on',\n",
       " 'earth']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## [v2 For Loop - Continue] Make a list of only the tokens in the document that are not punctuation or spaces \n",
    "## Lower the casing as well\n",
    "lemmas_list = []\n",
    "for token in doc:\n",
    "    if token.is_punct:\n",
    "        continue\n",
    "    if token.is_space:\n",
    "        continue\n",
    "\n",
    "    lemmas_list.append(token.lemma_.lower())\n",
    "\n",
    "lemmas_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de834ce5-41b3-4d8a-9228-410079777604",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0ef0456e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:15:11.339923Z",
     "iopub.status.busy": "2023-12-19T01:15:11.339311Z",
     "iopub.status.idle": "2023-12-19T01:15:11.344792Z",
     "shell.execute_reply": "2023-12-19T01:15:11.343537Z",
     "shell.execute_reply.started": "2023-12-19T01:15:11.339903Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.dothebouncy.com/smf',\n",
       " 'shameless',\n",
       " 'plug',\n",
       " 'good',\n",
       " 'rangers',\n",
       " 'forum',\n",
       " 'earth']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## [v1 List Comp] Make a list of all the tokens in the document that are not punctuation, spaces, or stop words\n",
    "[token.lemma_.lower() for token in doc if not token.is_punct and not token.is_space and not token.is_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "de72b19b-4d67-474e-9e1f-fabecbfca455",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:15:11.345622Z",
     "iopub.status.busy": "2023-12-19T01:15:11.345446Z",
     "iopub.status.idle": "2023-12-19T01:15:11.349147Z",
     "shell.execute_reply": "2023-12-19T01:15:11.348755Z",
     "shell.execute_reply.started": "2023-12-19T01:15:11.345572Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.dothebouncy.com/smf',\n",
       " 'shameless',\n",
       " 'plug',\n",
       " 'good',\n",
       " 'rangers',\n",
       " 'forum',\n",
       " 'earth']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## [v3 For Loop - Continue] Make a list of only the tokens in the document that are not punctuation or spaces \n",
    "## Lower the casing as well\n",
    "lemmas_list = []\n",
    "for token in doc:\n",
    "    if token.is_punct:\n",
    "        continue\n",
    "    if token.is_space:\n",
    "        continue\n",
    "    if token.is_stop:\n",
    "        continue\n",
    "\n",
    "    lemmas_list.append(token.lemma_.lower())\n",
    "\n",
    "lemmas_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b5314a-48e3-441c-85a1-c46542c00478",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "030bb742-e0c2-44f8-b3fc-0113695c0cc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:15:11.350267Z",
     "iopub.status.busy": "2023-12-19T01:15:11.349832Z",
     "iopub.status.idle": "2023-12-19T01:15:11.354401Z",
     "shell.execute_reply": "2023-12-19T01:15:11.354089Z",
     "shell.execute_reply.started": "2023-12-19T01:15:11.350251Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['shameless', 'plug', 'good', 'rangers', 'forum', 'earth']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## [v1 List Comp] Let's also remove the url\n",
    "[token.lemma_.lower() for token in doc if not token.is_punct and \n",
    " not token.is_space and not token.is_stop and \n",
    " not 'http' in token.lemma_.lower() and 'www' not in token.lemma_.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "645de9f6-3207-44ed-a481-e4060db02cb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:15:11.355334Z",
     "iopub.status.busy": "2023-12-19T01:15:11.355239Z",
     "iopub.status.idle": "2023-12-19T01:15:11.360198Z",
     "shell.execute_reply": "2023-12-19T01:15:11.359572Z",
     "shell.execute_reply.started": "2023-12-19T01:15:11.355325Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['shameless', 'plug', 'good', 'rangers', 'forum', 'earth']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## [v2 For Loop] Let's also remove the url\n",
    "## Lower the casing as well\n",
    "lemmas_list = []\n",
    "for token in doc:\n",
    "    if token.is_punct:\n",
    "        continue\n",
    "    if token.is_space:\n",
    "        continue\n",
    "    if token.is_stop:\n",
    "        continue\n",
    "\n",
    "    if 'http' in token.text.lower():\n",
    "        continue\n",
    "    if 'www' in token.text.lower():\n",
    "        continue\n",
    "        \n",
    "    lemmas_list.append(token.lemma_.lower())\n",
    "\n",
    "lemmas_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e4da8e",
   "metadata": {},
   "source": [
    "In order to use spaCy to process our entire dataframe, we will need to make a function and apply it to our text column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991184f2",
   "metadata": {},
   "source": [
    "## Preprocessing with spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "03918415",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:15:11.361302Z",
     "iopub.status.busy": "2023-12-19T01:15:11.361004Z",
     "iopub.status.idle": "2023-12-19T01:16:11.670494Z",
     "shell.execute_reply": "2023-12-19T01:16:11.670225Z",
     "shell.execute_reply.started": "2023-12-19T01:15:11.361280Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>length</th>\n",
       "      <th>lower_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>no_stops</th>\n",
       "      <th>no_stops_no_punct</th>\n",
       "      <th>spacy_lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>36</td>\n",
       "      <td>i`d have responded, if i were going</td>\n",
       "      <td>[i, `, d, have, responded, ,, if, i, were, going]</td>\n",
       "      <td>[`, responded, ,, going]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[i`d, respond, go]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>negative</td>\n",
       "      <td>46</td>\n",
       "      <td>sooo sad i will miss you here in san diego!!!</td>\n",
       "      <td>[sooo, sad, i, will, miss, you, here, in, san, diego, !, !, !]</td>\n",
       "      <td>[sooo, sad, miss, san, diego, !, !, !]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[sooo, sad, miss, san, diego]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>negative</td>\n",
       "      <td>25</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>[my, boss, is, bullying, me, ...]</td>\n",
       "      <td>[boss, bullying, ...]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[boss, bully]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>31</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>[what, interview, !, leave, me, alone]</td>\n",
       "      <td>[interview, !, leave, alone]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[interview, leave]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on the releases we already bought</td>\n",
       "      <td>negative</td>\n",
       "      <td>75</td>\n",
       "      <td>sons of ****, why couldn`t they put them on the releases we already bought</td>\n",
       "      <td>[sons, of, *, *, *, *, ,, why, couldn, `, t, they, put, them, on, the, releases, we, already, bought]</td>\n",
       "      <td>[sons, *, *, *, *, ,, `, put, releases, already, bought]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[son, couldn`t, release, buy]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                          text  \\\n",
       "0                                          I`d have responded, if I were going   \n",
       "1                                Sooo SAD I will miss you here in San Diego!!!   \n",
       "2                                                    my boss is bullying me...   \n",
       "3                                               what interview! leave me alone   \n",
       "4   Sons of ****, why couldn`t they put them on the releases we already bought   \n",
       "\n",
       "  sentiment  length  \\\n",
       "0   neutral      36   \n",
       "1  negative      46   \n",
       "2  negative      25   \n",
       "3  negative      31   \n",
       "4  negative      75   \n",
       "\n",
       "                                                                    lower_text  \\\n",
       "0                                          i`d have responded, if i were going   \n",
       "1                                sooo sad i will miss you here in san diego!!!   \n",
       "2                                                    my boss is bullying me...   \n",
       "3                                               what interview! leave me alone   \n",
       "4   sons of ****, why couldn`t they put them on the releases we already bought   \n",
       "\n",
       "                                                                                                  tokens  \\\n",
       "0                                                      [i, `, d, have, responded, ,, if, i, were, going]   \n",
       "1                                         [sooo, sad, i, will, miss, you, here, in, san, diego, !, !, !]   \n",
       "2                                                                      [my, boss, is, bullying, me, ...]   \n",
       "3                                                                 [what, interview, !, leave, me, alone]   \n",
       "4  [sons, of, *, *, *, *, ,, why, couldn, `, t, they, put, them, on, the, releases, we, already, bought]   \n",
       "\n",
       "                                                   no_stops no_stops_no_punct  \\\n",
       "0                                  [`, responded, ,, going]                []   \n",
       "1                    [sooo, sad, miss, san, diego, !, !, !]                []   \n",
       "2                                     [boss, bullying, ...]                []   \n",
       "3                              [interview, !, leave, alone]                []   \n",
       "4  [sons, *, *, *, *, ,, `, put, releases, already, bought]                []   \n",
       "\n",
       "                    spacy_lemmas  \n",
       "0             [i`d, respond, go]  \n",
       "1  [sooo, sad, miss, san, diego]  \n",
       "2                  [boss, bully]  \n",
       "3             [interview, leave]  \n",
       "4  [son, couldn`t, release, buy]  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## [V1 List Comp] Define a function to use spacy to process our text\n",
    "def spacy_process(text):\n",
    "        \"\"\"Lemmatize tokens, lower case, remove punctuation, spaces, and stop words\"\"\"\n",
    "        doc = nlp_model(text)\n",
    "        processed_doc = [token.lemma_.lower() for token in doc if not token.is_punct and \n",
    "                         not token.is_space and not token.is_stop and \n",
    "                         not 'http' in token.lemma_.lower() and 'www' not in token.lemma_.lower()]\n",
    "        return processed_doc\n",
    "\n",
    "## process the tweets using the spacy function\n",
    "df['spacy_lemmas'] = df['text'].apply(spacy_process)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "32df4827-73df-41d0-a064-af9fc130804a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:16:11.671122Z",
     "iopub.status.busy": "2023-12-19T01:16:11.671021Z",
     "iopub.status.idle": "2023-12-19T01:17:09.292508Z",
     "shell.execute_reply": "2023-12-19T01:17:09.292183Z",
     "shell.execute_reply.started": "2023-12-19T01:16:11.671113Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>length</th>\n",
       "      <th>lower_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>no_stops</th>\n",
       "      <th>no_stops_no_punct</th>\n",
       "      <th>spacy_lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>36</td>\n",
       "      <td>i`d have responded, if i were going</td>\n",
       "      <td>[i, `, d, have, responded, ,, if, i, were, going]</td>\n",
       "      <td>[`, responded, ,, going]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ , i`d, respond, ,, go]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>negative</td>\n",
       "      <td>46</td>\n",
       "      <td>sooo sad i will miss you here in san diego!!!</td>\n",
       "      <td>[sooo, sad, i, will, miss, you, here, in, san, diego, !, !, !]</td>\n",
       "      <td>[sooo, sad, miss, san, diego, !, !, !]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ , sooo, sad, miss, san, diego, !, !, !]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>negative</td>\n",
       "      <td>25</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>[my, boss, is, bullying, me, ...]</td>\n",
       "      <td>[boss, bullying, ...]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[boss, bully, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>31</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>[what, interview, !, leave, me, alone]</td>\n",
       "      <td>[interview, !, leave, alone]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ , interview, !, leave]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on the releases we already bought</td>\n",
       "      <td>negative</td>\n",
       "      <td>75</td>\n",
       "      <td>sons of ****, why couldn`t they put them on the releases we already bought</td>\n",
       "      <td>[sons, of, *, *, *, *, ,, why, couldn, `, t, they, put, them, on, the, releases, we, already, bought]</td>\n",
       "      <td>[sons, *, *, *, *, ,, `, put, releases, already, bought]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ , son, *, *, *, *, ,, couldn`t, release, buy]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                          text  \\\n",
       "0                                          I`d have responded, if I were going   \n",
       "1                                Sooo SAD I will miss you here in San Diego!!!   \n",
       "2                                                    my boss is bullying me...   \n",
       "3                                               what interview! leave me alone   \n",
       "4   Sons of ****, why couldn`t they put them on the releases we already bought   \n",
       "\n",
       "  sentiment  length  \\\n",
       "0   neutral      36   \n",
       "1  negative      46   \n",
       "2  negative      25   \n",
       "3  negative      31   \n",
       "4  negative      75   \n",
       "\n",
       "                                                                    lower_text  \\\n",
       "0                                          i`d have responded, if i were going   \n",
       "1                                sooo sad i will miss you here in san diego!!!   \n",
       "2                                                    my boss is bullying me...   \n",
       "3                                               what interview! leave me alone   \n",
       "4   sons of ****, why couldn`t they put them on the releases we already bought   \n",
       "\n",
       "                                                                                                  tokens  \\\n",
       "0                                                      [i, `, d, have, responded, ,, if, i, were, going]   \n",
       "1                                         [sooo, sad, i, will, miss, you, here, in, san, diego, !, !, !]   \n",
       "2                                                                      [my, boss, is, bullying, me, ...]   \n",
       "3                                                                 [what, interview, !, leave, me, alone]   \n",
       "4  [sons, of, *, *, *, *, ,, why, couldn, `, t, they, put, them, on, the, releases, we, already, bought]   \n",
       "\n",
       "                                                   no_stops no_stops_no_punct  \\\n",
       "0                                  [`, responded, ,, going]                []   \n",
       "1                    [sooo, sad, miss, san, diego, !, !, !]                []   \n",
       "2                                     [boss, bullying, ...]                []   \n",
       "3                              [interview, !, leave, alone]                []   \n",
       "4  [sons, *, *, *, *, ,, `, put, releases, already, bought]                []   \n",
       "\n",
       "                                      spacy_lemmas  \n",
       "0                         [ , i`d, respond, ,, go]  \n",
       "1        [ , sooo, sad, miss, san, diego, !, !, !]  \n",
       "2                               [boss, bully, ...]  \n",
       "3                         [ , interview, !, leave]  \n",
       "4  [ , son, *, *, *, *, ,, couldn`t, release, buy]  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [v2: for Loop] Define a function to use spacy to process our text\n",
    "def spacy_process(text):\n",
    "    \"\"\"Lemmatize tokens, lower case, remove punctuation, spaces, and stop words\"\"\"\n",
    "\n",
    "    # Make text into a document\n",
    "    doc = nlp_model(text)\n",
    "    \n",
    "    processed_doc = [ ]\n",
    "    \n",
    "    for token in doc:\n",
    "        # Check if token is stopword\n",
    "        if token.is_stop == True:\n",
    "            # Continue the loop with the next token\n",
    "            continue\n",
    "    \n",
    "        # Check if  is punct\n",
    "        if (remove_punct == True) and (token.is_punct == True):\n",
    "            continue\n",
    "    \n",
    "        # Check if  is whitespace\n",
    "        if (remove_punct == True) and (token.is_space == True):\n",
    "            continue\n",
    "\n",
    "        ## Check if URL\n",
    "        if (remove_urls==True) & ('http' in token.text.lower()):\n",
    "            continue\n",
    "            \n",
    "        ## Check if URL\n",
    "        if (remove_urls==True) & ('www' in token.text.lower()):\n",
    "            continue\n",
    "    \n",
    "        ## Determine final form of output list of tokens/lemmas\n",
    "        processed_doc.append(token.lemma_.lower())\n",
    "    \n",
    "    return processed_doc\n",
    "\n",
    "\n",
    "\n",
    "## process the tweets using the spacy function\n",
    "df['spacy_lemmas'] = df['text'].apply(spacy_process)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5795b4c6",
   "metadata": {},
   "source": [
    "We used spaCy to tokenize, lemmatize, and remove punctuation and stopwords from our text in one step!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd07ae60",
   "metadata": {},
   "source": [
    "Notice that the spaCy processed data is a little different than our previously processed data.  The text has been lemmatized and spaCy has a different list of stop words than NLTK.\n",
    "\n",
    "The learn platform has directions for how you can customize your spaCy stopword list and a function with more flexibility in how spaCy will process your data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0184944",
   "metadata": {},
   "source": [
    "# Ngrams\n",
    "\n",
    "ngrams combine multiple words into tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6a121550",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:17:09.293237Z",
     "iopub.status.busy": "2023-12-19T01:17:09.293130Z",
     "iopub.status.idle": "2023-12-19T01:17:09.295330Z",
     "shell.execute_reply": "2023-12-19T01:17:09.294994Z",
     "shell.execute_reply.started": "2023-12-19T01:17:09.293228Z"
    }
   },
   "outputs": [],
   "source": [
    "## Import the ngrams function\n",
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1fd9e047",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:17:09.295780Z",
     "iopub.status.busy": "2023-12-19T01:17:09.295690Z",
     "iopub.status.idle": "2023-12-19T01:17:09.304464Z",
     "shell.execute_reply": "2023-12-19T01:17:09.303998Z",
     "shell.execute_reply.started": "2023-12-19T01:17:09.295772Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.dothebouncy.com/smf',\n",
       " '-',\n",
       " 'shameless',\n",
       " 'plug',\n",
       " 'good',\n",
       " 'rangers',\n",
       " 'forum',\n",
       " 'earth']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Isolate the first lemmatized document\n",
    "lemma_doc = df['spacy_lemmas'][5]\n",
    "lemma_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f8e7af2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:17:09.305038Z",
     "iopub.status.busy": "2023-12-19T01:17:09.304950Z",
     "iopub.status.idle": "2023-12-19T01:17:09.308043Z",
     "shell.execute_reply": "2023-12-19T01:17:09.307545Z",
     "shell.execute_reply.started": "2023-12-19T01:17:09.305030Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('http://www.dothebouncy.com/smf', '-'),\n",
       " ('-', 'shameless'),\n",
       " ('shameless', 'plug'),\n",
       " ('plug', 'good'),\n",
       " ('good', 'rangers'),\n",
       " ('rangers', 'forum'),\n",
       " ('forum', 'earth')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create bigrams\n",
    "list(ngrams(lemma_doc,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7b3bb06c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:17:09.308853Z",
     "iopub.status.busy": "2023-12-19T01:17:09.308732Z",
     "iopub.status.idle": "2023-12-19T01:17:09.311709Z",
     "shell.execute_reply": "2023-12-19T01:17:09.311228Z",
     "shell.execute_reply.started": "2023-12-19T01:17:09.308844Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('http://www.dothebouncy.com/smf', '-', 'shameless'),\n",
       " ('-', 'shameless', 'plug'),\n",
       " ('shameless', 'plug', 'good'),\n",
       " ('plug', 'good', 'rangers'),\n",
       " ('good', 'rangers', 'forum'),\n",
       " ('rangers', 'forum', 'earth')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create trigrams\n",
    "list(ngrams(lemma_doc,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6857c3",
   "metadata": {},
   "source": [
    "## Applying `ngrams` to make a new column\n",
    "\n",
    "We need to make a function that returns a list of bigrams.  It won't work to just pass the ngrams function to `.apply()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d5bfc1fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:17:09.312481Z",
     "iopub.status.busy": "2023-12-19T01:17:09.312282Z",
     "iopub.status.idle": "2023-12-19T01:17:09.314531Z",
     "shell.execute_reply": "2023-12-19T01:17:09.314126Z",
     "shell.execute_reply.started": "2023-12-19T01:17:09.312471Z"
    }
   },
   "outputs": [],
   "source": [
    "## Create a function to create bigrams\n",
    "def make_bigrams(doc):\n",
    "    bigrams = ngrams(doc, 2)\n",
    "    bigrams = list(bigrams)\n",
    "    return bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9f624d0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:17:09.315421Z",
     "iopub.status.busy": "2023-12-19T01:17:09.315258Z",
     "iopub.status.idle": "2023-12-19T01:17:09.362434Z",
     "shell.execute_reply": "2023-12-19T01:17:09.362008Z",
     "shell.execute_reply.started": "2023-12-19T01:17:09.315410Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>length</th>\n",
       "      <th>lower_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>no_stops</th>\n",
       "      <th>no_stops_no_punct</th>\n",
       "      <th>spacy_lemmas</th>\n",
       "      <th>bigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>36</td>\n",
       "      <td>i`d have responded, if i were going</td>\n",
       "      <td>[i, `, d, have, responded, ,, if, i, were, going]</td>\n",
       "      <td>[`, responded, ,, going]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ , i`d, respond, ,, go]</td>\n",
       "      <td>[( , i`d), (i`d, respond), (respond, ,), (,, go)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>negative</td>\n",
       "      <td>46</td>\n",
       "      <td>sooo sad i will miss you here in san diego!!!</td>\n",
       "      <td>[sooo, sad, i, will, miss, you, here, in, san, diego, !, !, !]</td>\n",
       "      <td>[sooo, sad, miss, san, diego, !, !, !]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ , sooo, sad, miss, san, diego, !, !, !]</td>\n",
       "      <td>[( , sooo), (sooo, sad), (sad, miss), (miss, san), (san, diego), (diego, !), (!, !), (!, !)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>negative</td>\n",
       "      <td>25</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>[my, boss, is, bullying, me, ...]</td>\n",
       "      <td>[boss, bullying, ...]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[boss, bully, ...]</td>\n",
       "      <td>[(boss, bully), (bully, ...)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>31</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>[what, interview, !, leave, me, alone]</td>\n",
       "      <td>[interview, !, leave, alone]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ , interview, !, leave]</td>\n",
       "      <td>[( , interview), (interview, !), (!, leave)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on the releases we already bought</td>\n",
       "      <td>negative</td>\n",
       "      <td>75</td>\n",
       "      <td>sons of ****, why couldn`t they put them on the releases we already bought</td>\n",
       "      <td>[sons, of, *, *, *, *, ,, why, couldn, `, t, they, put, them, on, the, releases, we, already, bought]</td>\n",
       "      <td>[sons, *, *, *, *, ,, `, put, releases, already, bought]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ , son, *, *, *, *, ,, couldn`t, release, buy]</td>\n",
       "      <td>[( , son), (son, *), (*, *), (*, *), (*, *), (*, ,), (,, couldn`t), (couldn`t, release), (release, buy)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                          text  \\\n",
       "0                                          I`d have responded, if I were going   \n",
       "1                                Sooo SAD I will miss you here in San Diego!!!   \n",
       "2                                                    my boss is bullying me...   \n",
       "3                                               what interview! leave me alone   \n",
       "4   Sons of ****, why couldn`t they put them on the releases we already bought   \n",
       "\n",
       "  sentiment  length  \\\n",
       "0   neutral      36   \n",
       "1  negative      46   \n",
       "2  negative      25   \n",
       "3  negative      31   \n",
       "4  negative      75   \n",
       "\n",
       "                                                                    lower_text  \\\n",
       "0                                          i`d have responded, if i were going   \n",
       "1                                sooo sad i will miss you here in san diego!!!   \n",
       "2                                                    my boss is bullying me...   \n",
       "3                                               what interview! leave me alone   \n",
       "4   sons of ****, why couldn`t they put them on the releases we already bought   \n",
       "\n",
       "                                                                                                  tokens  \\\n",
       "0                                                      [i, `, d, have, responded, ,, if, i, were, going]   \n",
       "1                                         [sooo, sad, i, will, miss, you, here, in, san, diego, !, !, !]   \n",
       "2                                                                      [my, boss, is, bullying, me, ...]   \n",
       "3                                                                 [what, interview, !, leave, me, alone]   \n",
       "4  [sons, of, *, *, *, *, ,, why, couldn, `, t, they, put, them, on, the, releases, we, already, bought]   \n",
       "\n",
       "                                                   no_stops no_stops_no_punct  \\\n",
       "0                                  [`, responded, ,, going]                []   \n",
       "1                    [sooo, sad, miss, san, diego, !, !, !]                []   \n",
       "2                                     [boss, bullying, ...]                []   \n",
       "3                              [interview, !, leave, alone]                []   \n",
       "4  [sons, *, *, *, *, ,, `, put, releases, already, bought]                []   \n",
       "\n",
       "                                      spacy_lemmas  \\\n",
       "0                         [ , i`d, respond, ,, go]   \n",
       "1        [ , sooo, sad, miss, san, diego, !, !, !]   \n",
       "2                               [boss, bully, ...]   \n",
       "3                         [ , interview, !, leave]   \n",
       "4  [ , son, *, *, *, *, ,, couldn`t, release, buy]   \n",
       "\n",
       "                                                                                                    bigrams  \n",
       "0                                                         [( , i`d), (i`d, respond), (respond, ,), (,, go)]  \n",
       "1              [( , sooo), (sooo, sad), (sad, miss), (miss, san), (san, diego), (diego, !), (!, !), (!, !)]  \n",
       "2                                                                             [(boss, bully), (bully, ...)]  \n",
       "3                                                              [( , interview), (interview, !), (!, leave)]  \n",
       "4  [( , son), (son, *), (*, *), (*, *), (*, *), (*, ,), (,, couldn`t), (couldn`t, release), (release, buy)]  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add bigrams to the df with .apply()\n",
    "df['bigrams'] = df['spacy_lemmas'].apply(make_bigrams)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "402bbc8c-d4d9-45ed-a38e-322e775fa744",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:17:09.363104Z",
     "iopub.status.busy": "2023-12-19T01:17:09.363010Z",
     "iopub.status.idle": "2023-12-19T01:17:09.379509Z",
     "shell.execute_reply": "2023-12-19T01:17:09.378834Z",
     "shell.execute_reply.started": "2023-12-19T01:17:09.363096Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>length</th>\n",
       "      <th>lower_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>no_stops</th>\n",
       "      <th>no_stops_no_punct</th>\n",
       "      <th>spacy_lemmas</th>\n",
       "      <th>bigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>36</td>\n",
       "      <td>i`d have responded, if i were going</td>\n",
       "      <td>[i, `, d, have, responded, ,, if, i, were, going]</td>\n",
       "      <td>[`, responded, ,, going]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ , i`d, respond, ,, go]</td>\n",
       "      <td>[( , i`d), (i`d, respond), (respond, ,), (,, go)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>negative</td>\n",
       "      <td>46</td>\n",
       "      <td>sooo sad i will miss you here in san diego!!!</td>\n",
       "      <td>[sooo, sad, i, will, miss, you, here, in, san, diego, !, !, !]</td>\n",
       "      <td>[sooo, sad, miss, san, diego, !, !, !]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ , sooo, sad, miss, san, diego, !, !, !]</td>\n",
       "      <td>[( , sooo), (sooo, sad), (sad, miss), (miss, san), (san, diego), (diego, !), (!, !), (!, !)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>negative</td>\n",
       "      <td>25</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>[my, boss, is, bullying, me, ...]</td>\n",
       "      <td>[boss, bullying, ...]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[boss, bully, ...]</td>\n",
       "      <td>[(boss, bully), (bully, ...)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>31</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>[what, interview, !, leave, me, alone]</td>\n",
       "      <td>[interview, !, leave, alone]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ , interview, !, leave]</td>\n",
       "      <td>[( , interview), (interview, !), (!, leave)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on the releases we already bought</td>\n",
       "      <td>negative</td>\n",
       "      <td>75</td>\n",
       "      <td>sons of ****, why couldn`t they put them on the releases we already bought</td>\n",
       "      <td>[sons, of, *, *, *, *, ,, why, couldn, `, t, they, put, them, on, the, releases, we, already, bought]</td>\n",
       "      <td>[sons, *, *, *, *, ,, `, put, releases, already, bought]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ , son, *, *, *, *, ,, couldn`t, release, buy]</td>\n",
       "      <td>[( , son), (son, *), (*, *), (*, *), (*, *), (*, ,), (,, couldn`t), (couldn`t, release), (release, buy)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameless plugging for the best Rangers forum on earth</td>\n",
       "      <td>neutral</td>\n",
       "      <td>92</td>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameless plugging for the best rangers forum on earth</td>\n",
       "      <td>[http, :, //www.dothebouncy.com/smf, -, some, shameless, plugging, for, the, best, rangers, forum, on, earth]</td>\n",
       "      <td>[http, :, //www.dothebouncy.com/smf, -, shameless, plugging, best, rangers, forum, earth]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[http://www.dothebouncy.com/smf, -, shameless, plug, good, rangers, forum, earth]</td>\n",
       "      <td>[(http://www.dothebouncy.com/smf, -), (-, shameless), (shameless, plug), (plug, good), (good, rangers), (rangers, forum), (forum, earth)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2am feedings for the baby are fun when he is all smiles and coos</td>\n",
       "      <td>positive</td>\n",
       "      <td>64</td>\n",
       "      <td>2am feedings for the baby are fun when he is all smiles and coos</td>\n",
       "      <td>[2am, feedings, for, the, baby, are, fun, when, he, is, all, smiles, and, coos]</td>\n",
       "      <td>[2am, feedings, baby, fun, smiles, coos]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[2, feeding, baby, fun, smile, coo]</td>\n",
       "      <td>[(2, feeding), (feeding, baby), (baby, fun), (fun, smile), (smile, coo)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Soooo high</td>\n",
       "      <td>neutral</td>\n",
       "      <td>10</td>\n",
       "      <td>soooo high</td>\n",
       "      <td>[soooo, high]</td>\n",
       "      <td>[soooo, high]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[soooo, high]</td>\n",
       "      <td>[(soooo, high)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Both of you</td>\n",
       "      <td>neutral</td>\n",
       "      <td>12</td>\n",
       "      <td>both of you</td>\n",
       "      <td>[both, of, you]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ ]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Journey!? Wow... u just became cooler.  hehe... (is that possible!?)</td>\n",
       "      <td>positive</td>\n",
       "      <td>69</td>\n",
       "      <td>journey!? wow... u just became cooler.  hehe... (is that possible!?)</td>\n",
       "      <td>[journey, !, ?, wow, ..., u, just, became, cooler, ., hehe, ..., (, is, that, possible, !, ?, )]</td>\n",
       "      <td>[journey, !, ?, wow, ..., u, became, cooler, ., hehe, ..., (, possible, !, ?, )]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ , journey, !, ?, wow, ..., u, cool, .,  , hehe, ..., (, possible, !, ?, )]</td>\n",
       "      <td>[( , journey), (journey, !), (!, ?), (?, wow), (wow, ...), (..., u), (u, cool), (cool, .), (.,  ), ( , hehe), (hehe, ...), (..., (), ((, possible), (possible, !), (!, ?), (?, ))]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                           text  \\\n",
       "0                                                           I`d have responded, if I were going   \n",
       "1                                                 Sooo SAD I will miss you here in San Diego!!!   \n",
       "2                                                                     my boss is bullying me...   \n",
       "3                                                                what interview! leave me alone   \n",
       "4                    Sons of ****, why couldn`t they put them on the releases we already bought   \n",
       "5  http://www.dothebouncy.com/smf - some shameless plugging for the best Rangers forum on earth   \n",
       "6                              2am feedings for the baby are fun when he is all smiles and coos   \n",
       "7                                                                                    Soooo high   \n",
       "8                                                                                   Both of you   \n",
       "9                          Journey!? Wow... u just became cooler.  hehe... (is that possible!?)   \n",
       "\n",
       "  sentiment  length  \\\n",
       "0   neutral      36   \n",
       "1  negative      46   \n",
       "2  negative      25   \n",
       "3  negative      31   \n",
       "4  negative      75   \n",
       "5   neutral      92   \n",
       "6  positive      64   \n",
       "7   neutral      10   \n",
       "8   neutral      12   \n",
       "9  positive      69   \n",
       "\n",
       "                                                                                     lower_text  \\\n",
       "0                                                           i`d have responded, if i were going   \n",
       "1                                                 sooo sad i will miss you here in san diego!!!   \n",
       "2                                                                     my boss is bullying me...   \n",
       "3                                                                what interview! leave me alone   \n",
       "4                    sons of ****, why couldn`t they put them on the releases we already bought   \n",
       "5  http://www.dothebouncy.com/smf - some shameless plugging for the best rangers forum on earth   \n",
       "6                              2am feedings for the baby are fun when he is all smiles and coos   \n",
       "7                                                                                    soooo high   \n",
       "8                                                                                   both of you   \n",
       "9                          journey!? wow... u just became cooler.  hehe... (is that possible!?)   \n",
       "\n",
       "                                                                                                          tokens  \\\n",
       "0                                                              [i, `, d, have, responded, ,, if, i, were, going]   \n",
       "1                                                 [sooo, sad, i, will, miss, you, here, in, san, diego, !, !, !]   \n",
       "2                                                                              [my, boss, is, bullying, me, ...]   \n",
       "3                                                                         [what, interview, !, leave, me, alone]   \n",
       "4          [sons, of, *, *, *, *, ,, why, couldn, `, t, they, put, them, on, the, releases, we, already, bought]   \n",
       "5  [http, :, //www.dothebouncy.com/smf, -, some, shameless, plugging, for, the, best, rangers, forum, on, earth]   \n",
       "6                                [2am, feedings, for, the, baby, are, fun, when, he, is, all, smiles, and, coos]   \n",
       "7                                                                                                  [soooo, high]   \n",
       "8                                                                                                [both, of, you]   \n",
       "9               [journey, !, ?, wow, ..., u, just, became, cooler, ., hehe, ..., (, is, that, possible, !, ?, )]   \n",
       "\n",
       "                                                                                    no_stops  \\\n",
       "0                                                                   [`, responded, ,, going]   \n",
       "1                                                     [sooo, sad, miss, san, diego, !, !, !]   \n",
       "2                                                                      [boss, bullying, ...]   \n",
       "3                                                               [interview, !, leave, alone]   \n",
       "4                                   [sons, *, *, *, *, ,, `, put, releases, already, bought]   \n",
       "5  [http, :, //www.dothebouncy.com/smf, -, shameless, plugging, best, rangers, forum, earth]   \n",
       "6                                                   [2am, feedings, baby, fun, smiles, coos]   \n",
       "7                                                                              [soooo, high]   \n",
       "8                                                                                         []   \n",
       "9           [journey, !, ?, wow, ..., u, became, cooler, ., hehe, ..., (, possible, !, ?, )]   \n",
       "\n",
       "  no_stops_no_punct  \\\n",
       "0                []   \n",
       "1                []   \n",
       "2                []   \n",
       "3                []   \n",
       "4                []   \n",
       "5                []   \n",
       "6                []   \n",
       "7                []   \n",
       "8                []   \n",
       "9                []   \n",
       "\n",
       "                                                                        spacy_lemmas  \\\n",
       "0                                                           [ , i`d, respond, ,, go]   \n",
       "1                                          [ , sooo, sad, miss, san, diego, !, !, !]   \n",
       "2                                                                 [boss, bully, ...]   \n",
       "3                                                           [ , interview, !, leave]   \n",
       "4                                    [ , son, *, *, *, *, ,, couldn`t, release, buy]   \n",
       "5  [http://www.dothebouncy.com/smf, -, shameless, plug, good, rangers, forum, earth]   \n",
       "6                                                [2, feeding, baby, fun, smile, coo]   \n",
       "7                                                                      [soooo, high]   \n",
       "8                                                                                [ ]   \n",
       "9       [ , journey, !, ?, wow, ..., u, cool, .,  , hehe, ..., (, possible, !, ?, )]   \n",
       "\n",
       "                                                                                                                                                                              bigrams  \n",
       "0                                                                                                                                   [( , i`d), (i`d, respond), (respond, ,), (,, go)]  \n",
       "1                                                                                        [( , sooo), (sooo, sad), (sad, miss), (miss, san), (san, diego), (diego, !), (!, !), (!, !)]  \n",
       "2                                                                                                                                                       [(boss, bully), (bully, ...)]  \n",
       "3                                                                                                                                        [( , interview), (interview, !), (!, leave)]  \n",
       "4                                                                            [( , son), (son, *), (*, *), (*, *), (*, *), (*, ,), (,, couldn`t), (couldn`t, release), (release, buy)]  \n",
       "5                                           [(http://www.dothebouncy.com/smf, -), (-, shameless), (shameless, plug), (plug, good), (good, rangers), (rangers, forum), (forum, earth)]  \n",
       "6                                                                                                            [(2, feeding), (feeding, baby), (baby, fun), (fun, smile), (smile, coo)]  \n",
       "7                                                                                                                                                                     [(soooo, high)]  \n",
       "8                                                                                                                                                                                  []  \n",
       "9  [( , journey), (journey, !), (!, ?), (?, wow), (wow, ...), (..., u), (u, cool), (cool, .), (.,  ), ( , hehe), (hehe, ...), (..., (), ((, possible), (possible, !), (!, ?), (?, ))]  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d9b043",
   "metadata": {},
   "source": [
    "# Save the final data version for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9a038d6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:17:09.380238Z",
     "iopub.status.busy": "2023-12-19T01:17:09.380065Z",
     "iopub.status.idle": "2023-12-19T01:17:09.765615Z",
     "shell.execute_reply": "2023-12-19T01:17:09.765079Z",
     "shell.execute_reply.started": "2023-12-19T01:17:09.380218Z"
    }
   },
   "outputs": [],
   "source": [
    "## Save the processed data\n",
    "df.to_csv('../Data/processed_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e98a705f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:17:09.773677Z",
     "iopub.status.busy": "2023-12-19T01:17:09.773499Z",
     "iopub.status.idle": "2023-12-19T01:17:09.953584Z",
     "shell.execute_reply": "2023-12-19T01:17:09.953283Z",
     "shell.execute_reply.started": "2023-12-19T01:17:09.773664Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Data/processed_data.joblib']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Save the processed data - as a joblib\n",
    "import joblib\n",
    "joblib.dump(df,'../Data/processed_data.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e2ff85-20c9-41b1-a11f-66c61b50cbc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
