{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f34a8583-3d57-4f07-8a10-9459ee3cdb09",
   "metadata": {},
   "source": [
    "# SOLUTIONS: Advanced ML Week 1, Lecture 1: Working with and Preparing Text Data\n",
    "\n",
    "In this notebook we will be preparing Twitter (X) Tweets for sentiment analysis.  Sentiment analysis is a common text classification challenge to determine whether a text is positive or negative.  \n",
    "\n",
    "This is useful for companies that want to analyze large numbers of documents, tweets, reviews, etc., to determine public sentiment about a product or service.\n",
    "\n",
    "The data was originally gathered from Twitter (now X) and hand-labeled.  Of course there will be some human bias in the labeling.  It was downloaded from Kaggle at this site: [Kaggle Twitter Tweets Sentiment Dataset](https://www.kaggle.com/datasets/yasserh/twitter-tweets-sentiment-dataset/)\n",
    "\n",
    "There are 3 classes: positive, negative, and neutral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a6c695c-5cfd-4069-aacf-dacd0457e3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import necessary packages\n",
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c0645a-3d8a-41f9-a678-23b5862ac8a2",
   "metadata": {},
   "source": [
    "# Load the Data\n",
    "\n",
    "We will download our **corpus** of tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f666473-51b7-4c60-8ce6-ae94e5b3d73f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on the releases we already bought</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID  \\\n",
       "0  cb774db0d1   \n",
       "1  549e992a42   \n",
       "2  088c60f138   \n",
       "3  9642c003ef   \n",
       "4  358bd9e861   \n",
       "\n",
       "                                                                          text  \\\n",
       "0                                          I`d have responded, if I were going   \n",
       "1                                Sooo SAD I will miss you here in San Diego!!!   \n",
       "2                                                    my boss is bullying me...   \n",
       "3                                               what interview! leave me alone   \n",
       "4   Sons of ****, why couldn`t they put them on the releases we already bought   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going   neutral  \n",
       "1                             Sooo SAD  negative  \n",
       "2                          bullying me  negative  \n",
       "3                       leave me alone  negative  \n",
       "4                        Sons of ****,  negative  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Download corpus of tweets\n",
    "df = pd.read_csv('../Data/archive.zip')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15206203-a97b-448d-b5e9-a95c511ec56a",
   "metadata": {},
   "source": [
    "# Some light EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12e60c31-28a8-48a2-a150-cc2eb9ed3f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27481 entries, 0 to 27480\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   textID         27481 non-null  object\n",
      " 1   text           27480 non-null  object\n",
      " 2   selected_text  27480 non-null  object\n",
      " 3   sentiment      27481 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 858.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc3e96d1-975b-493b-9551-9e242871df7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafde953-8792-47b9-861e-3f53b6e3a177",
   "metadata": {},
   "source": [
    "# Some Light Data Cleaning\n",
    "\n",
    "We see that our **corpus** has 27481 **documents**, each with an ID, the full text, a shortened version, and the labeled sentiment.\n",
    "\n",
    "Interestingly, one of the tweets has no text!  We definitely want to get rid of that.  We will also drop the `textID` and `selected_text` columns.  We are going to use the entire text of each tweet, not just a subset.\n",
    "\n",
    "We will keep the label, `sentiment` for later classification and analysis tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64be5747-3e29-4745-ab38-c25e09255dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['textID', 'selected_text'])\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bbbbcd7d-1e2f-4d44-bb98-43ece33d3ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 27480 entries, 0 to 27480\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   text       27480 non-null  object\n",
      " 1   sentiment  27480 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 644.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922b390c-c90c-46d4-be9f-061e8a66f2f2",
   "metadata": {},
   "source": [
    "# Some More EDA\n",
    "Let's look at some aspects of this text.\n",
    "* What do the **documents** look like?\n",
    "* How long do the tend to be?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0656c034-5ce8-4214-8147-a18f1150699f",
   "metadata": {},
   "source": [
    "## View some sample tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f2e8add-e130-49ac-8ffa-9dcb7d59568d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                             I`d have responded, if I were going\n",
       "1                                                   Sooo SAD I will miss you here in San Diego!!!\n",
       "2                                                                       my boss is bullying me...\n",
       "3                                                                  what interview! leave me alone\n",
       "4                      Sons of ****, why couldn`t they put them on the releases we already bought\n",
       "5    http://www.dothebouncy.com/smf - some shameless plugging for the best Rangers forum on earth\n",
       "6                                2am feedings for the baby are fun when he is all smiles and coos\n",
       "7                                                                                      Soooo high\n",
       "8                                                                                     Both of you\n",
       "9                            Journey!? Wow... u just became cooler.  hehe... (is that possible!?)\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Expand how many characters pandas will show\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "## Display some of the documents (tweets)\n",
    "df['text'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930cd2bd-5fbf-4d38-b932-05ae2de1e25e",
   "metadata": {},
   "source": [
    "## Get some statistics on the length of **documents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e65b4f6-78ec-4344-aca0-83c43a78336b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>negative</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>negative</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on the releases we already bought</td>\n",
       "      <td>negative</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameless plugging for the best Rangers forum on earth</td>\n",
       "      <td>neutral</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2am feedings for the baby are fun when he is all smiles and coos</td>\n",
       "      <td>positive</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Soooo high</td>\n",
       "      <td>neutral</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Both of you</td>\n",
       "      <td>neutral</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Journey!? Wow... u just became cooler.  hehe... (is that possible!?)</td>\n",
       "      <td>positive</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                           text  \\\n",
       "0                                                           I`d have responded, if I were going   \n",
       "1                                                 Sooo SAD I will miss you here in San Diego!!!   \n",
       "2                                                                     my boss is bullying me...   \n",
       "3                                                                what interview! leave me alone   \n",
       "4                    Sons of ****, why couldn`t they put them on the releases we already bought   \n",
       "5  http://www.dothebouncy.com/smf - some shameless plugging for the best Rangers forum on earth   \n",
       "6                              2am feedings for the baby are fun when he is all smiles and coos   \n",
       "7                                                                                    Soooo high   \n",
       "8                                                                                   Both of you   \n",
       "9                          Journey!? Wow... u just became cooler.  hehe... (is that possible!?)   \n",
       "\n",
       "  sentiment  length  \n",
       "0   neutral      36  \n",
       "1  negative      46  \n",
       "2  negative      25  \n",
       "3  negative      31  \n",
       "4  negative      75  \n",
       "5   neutral      92  \n",
       "6  positive      64  \n",
       "7   neutral      10  \n",
       "8   neutral      12  \n",
       "9  positive      69  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Determine the length of each tweet\n",
    "df['length'] = df['text'].map(len)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62170df2-9dda-479d-b003-37a401889bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    27480.000000\n",
       "mean        68.330022\n",
       "std         35.603870\n",
       "min          3.000000\n",
       "25%         39.000000\n",
       "50%         64.000000\n",
       "75%         97.000000\n",
       "max        141.000000\n",
       "Name: length, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Analyze the statistics of the lengths\n",
    "df['length'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45dafca-dc80-4cba-862d-e9ba98de19dd",
   "metadata": {},
   "source": [
    "The tweets have an mean length of 68 characters and a median of 64. They range from 3 to 141 characters with a standard deviation of 35.  The middle 50% are between 39 and 97 characters in length.\n",
    "\n",
    "This gives us some idea of how long they tend to be."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8f7818-5a2e-48f2-87bf-29678b7f9be6",
   "metadata": {},
   "source": [
    "# Text Normalization with NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a869f6-073e-4281-b21a-33aba2fdd553",
   "metadata": {},
   "source": [
    "## Normalizing Casing\n",
    "\n",
    "It's common practice to lower the casing of the text in our documents to contribut to normalizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "550db04b-32a7-4270-9420-e6da4eaadb1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>length</th>\n",
       "      <th>lower_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>36</td>\n",
       "      <td>i`d have responded, if i were going</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>negative</td>\n",
       "      <td>46</td>\n",
       "      <td>sooo sad i will miss you here in san diego!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>negative</td>\n",
       "      <td>25</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>31</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on the releases we already bought</td>\n",
       "      <td>negative</td>\n",
       "      <td>75</td>\n",
       "      <td>sons of ****, why couldn`t they put them on the releases we already bought</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                          text  \\\n",
       "0                                          I`d have responded, if I were going   \n",
       "1                                Sooo SAD I will miss you here in San Diego!!!   \n",
       "2                                                    my boss is bullying me...   \n",
       "3                                               what interview! leave me alone   \n",
       "4   Sons of ****, why couldn`t they put them on the releases we already bought   \n",
       "\n",
       "  sentiment  length  \\\n",
       "0   neutral      36   \n",
       "1  negative      46   \n",
       "2  negative      25   \n",
       "3  negative      31   \n",
       "4  negative      75   \n",
       "\n",
       "                                                                    lower_text  \n",
       "0                                          i`d have responded, if i were going  \n",
       "1                                sooo sad i will miss you here in san diego!!!  \n",
       "2                                                    my boss is bullying me...  \n",
       "3                                               what interview! leave me alone  \n",
       "4   sons of ****, why couldn`t they put them on the releases we already bought  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lower_text'] = df['text'].str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b174777b-b52a-4260-b486-b75ec1a2ba0f",
   "metadata": {},
   "source": [
    "## Tokenizing\n",
    "\n",
    "Tokenizing text into single word tokens is simple in Python.  We can just use `str.split()`.  The default separator for `.split()` is one space, so `' '`.\n",
    "\n",
    "We can access Pandas' string accessor with `df.str.<method>`.  This allows us to apply string methods to all rows in a column.\n",
    "\n",
    "When processing text, if memory allows, it can be useful to keep many versions of your text: tokenize, lemmatized, no stop words, etc.  Some analysis or modeling packages expect tokenized data and others do not.  We often want to use different versions for different kinds of analysis, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b244d34-3f00-4b0a-af13-d9f0ee324398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>length</th>\n",
       "      <th>lower_text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>36</td>\n",
       "      <td>i`d have responded, if i were going</td>\n",
       "      <td>[i`d, have, responded,, if, i, were, going]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>negative</td>\n",
       "      <td>46</td>\n",
       "      <td>sooo sad i will miss you here in san diego!!!</td>\n",
       "      <td>[sooo, sad, i, will, miss, you, here, in, san, diego!!!]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>negative</td>\n",
       "      <td>25</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>[my, boss, is, bullying, me...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>31</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>[what, interview!, leave, me, alone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on the releases we already bought</td>\n",
       "      <td>negative</td>\n",
       "      <td>75</td>\n",
       "      <td>sons of ****, why couldn`t they put them on the releases we already bought</td>\n",
       "      <td>[sons, of, ****,, why, couldn`t, they, put, them, on, the, releases, we, already, bought]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                          text  \\\n",
       "0                                          I`d have responded, if I were going   \n",
       "1                                Sooo SAD I will miss you here in San Diego!!!   \n",
       "2                                                    my boss is bullying me...   \n",
       "3                                               what interview! leave me alone   \n",
       "4   Sons of ****, why couldn`t they put them on the releases we already bought   \n",
       "\n",
       "  sentiment  length  \\\n",
       "0   neutral      36   \n",
       "1  negative      46   \n",
       "2  negative      25   \n",
       "3  negative      31   \n",
       "4  negative      75   \n",
       "\n",
       "                                                                    lower_text  \\\n",
       "0                                          i`d have responded, if i were going   \n",
       "1                                sooo sad i will miss you here in san diego!!!   \n",
       "2                                                    my boss is bullying me...   \n",
       "3                                               what interview! leave me alone   \n",
       "4   sons of ****, why couldn`t they put them on the releases we already bought   \n",
       "\n",
       "                                                                                      tokens  \n",
       "0                                                [i`d, have, responded,, if, i, were, going]  \n",
       "1                                   [sooo, sad, i, will, miss, you, here, in, san, diego!!!]  \n",
       "2                                                            [my, boss, is, bullying, me...]  \n",
       "3                                                       [what, interview!, leave, me, alone]  \n",
       "4  [sons, of, ****,, why, couldn`t, they, put, them, on, the, releases, we, already, bought]  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokens'] = df['lower_text'].str.split()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68391d27-b08b-469a-b5cc-c2571b849b14",
   "metadata": {},
   "source": [
    "### Better way to tokenize data\n",
    "\n",
    "NLTK has a more sophisticated tokenization function that will isolate things like punctuation as well.  This way 'hooray' and 'hooray!!!' will be the same token.\n",
    "\n",
    "In order for NLTK to recognize the punctuation, we will need to download the 'punkt' data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "99cb8036-ffbe-4365-aacc-3ee5cc5e05e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\caell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>length</th>\n",
       "      <th>lower_text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>36</td>\n",
       "      <td>i`d have responded, if i were going</td>\n",
       "      <td>[i, `, d, have, responded, ,, if, i, were, going]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>negative</td>\n",
       "      <td>46</td>\n",
       "      <td>sooo sad i will miss you here in san diego!!!</td>\n",
       "      <td>[sooo, sad, i, will, miss, you, here, in, san, diego, !, !, !]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>negative</td>\n",
       "      <td>25</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>[my, boss, is, bullying, me, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>31</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>[what, interview, !, leave, me, alone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on the releases we already bought</td>\n",
       "      <td>negative</td>\n",
       "      <td>75</td>\n",
       "      <td>sons of ****, why couldn`t they put them on the releases we already bought</td>\n",
       "      <td>[sons, of, *, *, *, *, ,, why, couldn, `, t, they, put, them, on, the, releases, we, already, bought]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                          text  \\\n",
       "0                                          I`d have responded, if I were going   \n",
       "1                                Sooo SAD I will miss you here in San Diego!!!   \n",
       "2                                                    my boss is bullying me...   \n",
       "3                                               what interview! leave me alone   \n",
       "4   Sons of ****, why couldn`t they put them on the releases we already bought   \n",
       "\n",
       "  sentiment  length  \\\n",
       "0   neutral      36   \n",
       "1  negative      46   \n",
       "2  negative      25   \n",
       "3  negative      31   \n",
       "4  negative      75   \n",
       "\n",
       "                                                                    lower_text  \\\n",
       "0                                          i`d have responded, if i were going   \n",
       "1                                sooo sad i will miss you here in san diego!!!   \n",
       "2                                                    my boss is bullying me...   \n",
       "3                                               what interview! leave me alone   \n",
       "4   sons of ****, why couldn`t they put them on the releases we already bought   \n",
       "\n",
       "                                                                                                  tokens  \n",
       "0                                                      [i, `, d, have, responded, ,, if, i, were, going]  \n",
       "1                                         [sooo, sad, i, will, miss, you, here, in, san, diego, !, !, !]  \n",
       "2                                                                      [my, boss, is, bullying, me, ...]  \n",
       "3                                                                 [what, interview, !, leave, me, alone]  \n",
       "4  [sons, of, *, *, *, *, ,, why, couldn, `, t, they, put, them, on, the, releases, we, already, bought]  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Download punkt\n",
    "nltk.download('punkt')\n",
    "\n",
    "df['tokens'] = df['lower_text'].apply(nltk.word_tokenize)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92f435f-e144-4b72-8c07-3249dae5b164",
   "metadata": {},
   "source": [
    "## Remove Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "32e91158-047d-4ba7-9a6b-67ae623a33b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\caell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Download NLTK stopword list\n",
    "nltk.download('stopwords')\n",
    "\n",
    "## Load the English stop words.\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "stop_words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b32bd5a-fe7d-4766-baec-55ceb0f2f78c",
   "metadata": {},
   "source": [
    "<font color=red> NOTICE </font> that all of the stop words are lower case.  It's necessary to ensure that your tokens are all lower case before using this list to remove stop words.\n",
    "\n",
    "To remove the stop words from each document, we will apply a function that will check each word in the list of tokens against the list of stopwords and remove them if they are in the list.  More specifically, it will only save them if they are NOT in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b7cd190-07ee-40ee-b6c2-4c8639ff4cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>length</th>\n",
       "      <th>lower_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>no_stops</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>36</td>\n",
       "      <td>i`d have responded, if i were going</td>\n",
       "      <td>[i, `, d, have, responded, ,, if, i, were, going]</td>\n",
       "      <td>[`, responded, ,, going]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>negative</td>\n",
       "      <td>46</td>\n",
       "      <td>sooo sad i will miss you here in san diego!!!</td>\n",
       "      <td>[sooo, sad, i, will, miss, you, here, in, san, diego, !, !, !]</td>\n",
       "      <td>[sooo, sad, miss, san, diego, !, !, !]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>negative</td>\n",
       "      <td>25</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>[my, boss, is, bullying, me, ...]</td>\n",
       "      <td>[boss, bullying, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>31</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>[what, interview, !, leave, me, alone]</td>\n",
       "      <td>[interview, !, leave, alone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on the releases we already bought</td>\n",
       "      <td>negative</td>\n",
       "      <td>75</td>\n",
       "      <td>sons of ****, why couldn`t they put them on the releases we already bought</td>\n",
       "      <td>[sons, of, *, *, *, *, ,, why, couldn, `, t, they, put, them, on, the, releases, we, already, bought]</td>\n",
       "      <td>[sons, *, *, *, *, ,, `, put, releases, already, bought]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                          text  \\\n",
       "0                                          I`d have responded, if I were going   \n",
       "1                                Sooo SAD I will miss you here in San Diego!!!   \n",
       "2                                                    my boss is bullying me...   \n",
       "3                                               what interview! leave me alone   \n",
       "4   Sons of ****, why couldn`t they put them on the releases we already bought   \n",
       "\n",
       "  sentiment  length  \\\n",
       "0   neutral      36   \n",
       "1  negative      46   \n",
       "2  negative      25   \n",
       "3  negative      31   \n",
       "4  negative      75   \n",
       "\n",
       "                                                                    lower_text  \\\n",
       "0                                          i`d have responded, if i were going   \n",
       "1                                sooo sad i will miss you here in san diego!!!   \n",
       "2                                                    my boss is bullying me...   \n",
       "3                                               what interview! leave me alone   \n",
       "4   sons of ****, why couldn`t they put them on the releases we already bought   \n",
       "\n",
       "                                                                                                  tokens  \\\n",
       "0                                                      [i, `, d, have, responded, ,, if, i, were, going]   \n",
       "1                                         [sooo, sad, i, will, miss, you, here, in, san, diego, !, !, !]   \n",
       "2                                                                      [my, boss, is, bullying, me, ...]   \n",
       "3                                                                 [what, interview, !, leave, me, alone]   \n",
       "4  [sons, of, *, *, *, *, ,, why, couldn, `, t, they, put, them, on, the, releases, we, already, bought]   \n",
       "\n",
       "                                                   no_stops  \n",
       "0                                  [`, responded, ,, going]  \n",
       "1                    [sooo, sad, miss, san, diego, !, !, !]  \n",
       "2                                     [boss, bullying, ...]  \n",
       "3                              [interview, !, leave, alone]  \n",
       "4  [sons, *, *, *, *, ,, `, put, releases, already, bought]  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Remove Stopwords Function\n",
    "def remove_stopwords(tokens):\n",
    "    no_stops = [token for token in tokens if not token in stop_words]\n",
    "    return no_stops\n",
    "\n",
    "df['no_stops'] = df['tokens'].map(remove_stopwords)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29e8234-98a9-4e5b-8994-71be25afc15d",
   "metadata": {},
   "source": [
    "## Remove Punctuation\n",
    "\n",
    "We can remove punctuation in a similar that we removed stop words.  However, we will get our list of punctuation from the built in Python string library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "81cb2857-8b5f-4c61-99f0-3a4151f0c0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "## Import built-in String Libary\n",
    "from string import punctuation\n",
    "print(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2c02a29f-39f3-4671-93f8-0452c223fe61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>length</th>\n",
       "      <th>lower_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>no_stops</th>\n",
       "      <th>no_stops_no_punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>36</td>\n",
       "      <td>i`d have responded, if i were going</td>\n",
       "      <td>[i, `, d, have, responded, ,, if, i, were, going]</td>\n",
       "      <td>[`, responded, ,, going]</td>\n",
       "      <td>[responded, going]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>negative</td>\n",
       "      <td>46</td>\n",
       "      <td>sooo sad i will miss you here in san diego!!!</td>\n",
       "      <td>[sooo, sad, i, will, miss, you, here, in, san, diego, !, !, !]</td>\n",
       "      <td>[sooo, sad, miss, san, diego, !, !, !]</td>\n",
       "      <td>[sooo, sad, miss, san, diego]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>negative</td>\n",
       "      <td>25</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>[my, boss, is, bullying, me, ...]</td>\n",
       "      <td>[boss, bullying, ...]</td>\n",
       "      <td>[boss, bullying, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>31</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>[what, interview, !, leave, me, alone]</td>\n",
       "      <td>[interview, !, leave, alone]</td>\n",
       "      <td>[interview, leave, alone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on the releases we already bought</td>\n",
       "      <td>negative</td>\n",
       "      <td>75</td>\n",
       "      <td>sons of ****, why couldn`t they put them on the releases we already bought</td>\n",
       "      <td>[sons, of, *, *, *, *, ,, why, couldn, `, t, they, put, them, on, the, releases, we, already, bought]</td>\n",
       "      <td>[sons, *, *, *, *, ,, `, put, releases, already, bought]</td>\n",
       "      <td>[sons, put, releases, already, bought]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                          text  \\\n",
       "0                                          I`d have responded, if I were going   \n",
       "1                                Sooo SAD I will miss you here in San Diego!!!   \n",
       "2                                                    my boss is bullying me...   \n",
       "3                                               what interview! leave me alone   \n",
       "4   Sons of ****, why couldn`t they put them on the releases we already bought   \n",
       "\n",
       "  sentiment  length  \\\n",
       "0   neutral      36   \n",
       "1  negative      46   \n",
       "2  negative      25   \n",
       "3  negative      31   \n",
       "4  negative      75   \n",
       "\n",
       "                                                                    lower_text  \\\n",
       "0                                          i`d have responded, if i were going   \n",
       "1                                sooo sad i will miss you here in san diego!!!   \n",
       "2                                                    my boss is bullying me...   \n",
       "3                                               what interview! leave me alone   \n",
       "4   sons of ****, why couldn`t they put them on the releases we already bought   \n",
       "\n",
       "                                                                                                  tokens  \\\n",
       "0                                                      [i, `, d, have, responded, ,, if, i, were, going]   \n",
       "1                                         [sooo, sad, i, will, miss, you, here, in, san, diego, !, !, !]   \n",
       "2                                                                      [my, boss, is, bullying, me, ...]   \n",
       "3                                                                 [what, interview, !, leave, me, alone]   \n",
       "4  [sons, of, *, *, *, *, ,, why, couldn, `, t, they, put, them, on, the, releases, we, already, bought]   \n",
       "\n",
       "                                                   no_stops  \\\n",
       "0                                  [`, responded, ,, going]   \n",
       "1                    [sooo, sad, miss, san, diego, !, !, !]   \n",
       "2                                     [boss, bullying, ...]   \n",
       "3                              [interview, !, leave, alone]   \n",
       "4  [sons, *, *, *, *, ,, `, put, releases, already, bought]   \n",
       "\n",
       "                        no_stops_no_punct  \n",
       "0                      [responded, going]  \n",
       "1           [sooo, sad, miss, san, diego]  \n",
       "2                   [boss, bullying, ...]  \n",
       "3               [interview, leave, alone]  \n",
       "4  [sons, put, releases, already, bought]  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_punct(tokens):\n",
    "    no_punct = [token for token in tokens if not token in punctuation]\n",
    "    return no_punct\n",
    "\n",
    "df['no_stops_no_punct'] = df['no_stops'].apply(remove_punct)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beac0458-1764-4f82-ba99-0dd7ee47a16e",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Note how many fewer tokens we have in our `no_stops_no_punct` tokens than in our original.  However, some information was lost, but a lot was also retained.  \n",
    "\n",
    "Normalization is a huge part of the NLP process and is always a balance between reducing the size of our vocabulary and therefor simplifying our models, and retaining enough information for the model to extract some meaningful patterns in the texts.  \n",
    "\n",
    "There are a lot of choices here to make."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ed88e6-d9b1-4a54-943c-76d26209f01b",
   "metadata": {},
   "source": [
    "# Normalizing Text with spaCy\n",
    "\n",
    "The spaCy Python package provides text processing pipelines that can do many of these operations, plus much more complicated processing, very fast and in many fewer steps.  For this reason it is a very popular tool.  \n",
    "\n",
    "It utilizes pretrained language models that can recognize things like parts of speech and named entities (people, specific places, currency, etc.)\n",
    "\n",
    "spaCy was not included in your original dojo_env, so you will need to install if if you have not already.\n",
    "\n",
    "We will also download the pretrained english language model trained on millions of web documents.  We will use the small sized one for efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a3e87dc-befc-4cc1-b970-75fcac2026fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\caell\\anaconda3\\envs\\dojo-env\\lib\\site-packages (3.7.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\caell\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\caell\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\caell\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\caell\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\caell\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in c:\\users\\caell\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy) (8.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\caell\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\caell\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\caell\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\caell\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\caell\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\caell\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\caell\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\caell\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy) (2.29.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\caell\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy) (2.5.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\caell\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\caell\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy) (66.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\caell\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy) (23.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\caell\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\caell\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy) (1.23.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\caell\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in c:\\users\\caell\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.14.5)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\caell\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\caell\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\caell\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\caell\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\caell\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.5.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\caell\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\caell\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\caell\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\caell\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\caell\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\caell\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from jinja2->spacy) (2.1.1)\n",
      "\u001b[38;5;2m Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "## Install spacy if necessary\n",
    "!pip install spacy\n",
    "\n",
    "import spacy\n",
    "\n",
    "## Download the English small-sized model trained on web documents if necessary\n",
    "spacy.cli.download('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The spaCy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "416eaea3-add2-481f-b77e-79c67901f2ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load the model.  Disable Named Entity Recognizer (too slow)\n",
    "nlp_model = spacy.load('en_core_web_sm', disable='ner')\n",
    "nlp_model.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have our model, and we can apply it like a function.  It expects a string of text as the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " I`d have responded, if I were going"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Process a document with the model\n",
    "doc = nlp_model(df['text'][0])\n",
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The document is a collection of tokens we can iterate over"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documents and Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ , I`d, have, responded, ,, if, I, were, going]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Display the tokens in the document\n",
    "[token for token in doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each token is much more than a string.  It"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "going\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "spacy.tokens.token.Token"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Isolate the last token in the document\n",
    "word = doc[-1]\n",
    "\n",
    "## Display the text and type of the token\n",
    "print(word)\n",
    "type(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each has many attributes that we can take advantage of, such as the lemma form and whether it is punctuation or space, and whether it is a stop word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Display the lemmatized form of the token\n",
    "word.lemma_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check whether the token is punctuation\n",
    "word.is_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check whether the token is a space\n",
    "word.is_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spacy can even determine the part of speech that the token is!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VERB'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check the part of speech of the token\n",
    "word.pos_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SPACE', 'PROPN', 'AUX', 'VERB', 'PUNCT', 'SCONJ', 'PRON', 'AUX', 'VERB']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token.pos_ for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ', 'I`d', 'have', 'respond', ',', 'if', 'I', 'be', 'go']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Make a list of the lemmas for each token in the document\n",
    "[token.lemma_ for token in doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the spaCy lemmatization does not automatically lower the casing of words when lemmatizing.  Let's go ahead and make sure they are all lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i`d', 'have', 'respond', 'if', 'i', 'be', 'go']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Make a list of only the tokens in the document that are not punctuation or spaces\n",
    "## Lower the casing as well\n",
    "[token.lemma_.lower() for token in doc if not token.is_punct and not token.is_space]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i`d', 'respond', 'go']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Make a list of all the tokens in the document that are not punctuation, spaces, or stop words\n",
    "[token.lemma_.lower() for token in doc if not token.is_punct and not token.is_space and not token.is_stop]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use spaCy to process our entire dataframe, we will need to make a function and apply it to our text column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing with spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>length</th>\n",
       "      <th>lower_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>no_stops</th>\n",
       "      <th>no_stops_no_punct</th>\n",
       "      <th>spacy_lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>36</td>\n",
       "      <td>i`d have responded, if i were going</td>\n",
       "      <td>[i, `, d, have, responded, ,, if, i, were, going]</td>\n",
       "      <td>[`, responded, ,, going]</td>\n",
       "      <td>[responded, going]</td>\n",
       "      <td>[i`d, respond, go]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>negative</td>\n",
       "      <td>46</td>\n",
       "      <td>sooo sad i will miss you here in san diego!!!</td>\n",
       "      <td>[sooo, sad, i, will, miss, you, here, in, san, diego, !, !, !]</td>\n",
       "      <td>[sooo, sad, miss, san, diego, !, !, !]</td>\n",
       "      <td>[sooo, sad, miss, san, diego]</td>\n",
       "      <td>[sooo, sad, miss, san, diego]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>negative</td>\n",
       "      <td>25</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>[my, boss, is, bullying, me, ...]</td>\n",
       "      <td>[boss, bullying, ...]</td>\n",
       "      <td>[boss, bullying, ...]</td>\n",
       "      <td>[boss, bully]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>31</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>[what, interview, !, leave, me, alone]</td>\n",
       "      <td>[interview, !, leave, alone]</td>\n",
       "      <td>[interview, leave, alone]</td>\n",
       "      <td>[interview, leave]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on the releases we already bought</td>\n",
       "      <td>negative</td>\n",
       "      <td>75</td>\n",
       "      <td>sons of ****, why couldn`t they put them on the releases we already bought</td>\n",
       "      <td>[sons, of, *, *, *, *, ,, why, couldn, `, t, they, put, them, on, the, releases, we, already, bought]</td>\n",
       "      <td>[sons, *, *, *, *, ,, `, put, releases, already, bought]</td>\n",
       "      <td>[sons, put, releases, already, bought]</td>\n",
       "      <td>[son, couldn`t, release, buy]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                          text  \\\n",
       "0                                          I`d have responded, if I were going   \n",
       "1                                Sooo SAD I will miss you here in San Diego!!!   \n",
       "2                                                    my boss is bullying me...   \n",
       "3                                               what interview! leave me alone   \n",
       "4   Sons of ****, why couldn`t they put them on the releases we already bought   \n",
       "\n",
       "  sentiment  length  \\\n",
       "0   neutral      36   \n",
       "1  negative      46   \n",
       "2  negative      25   \n",
       "3  negative      31   \n",
       "4  negative      75   \n",
       "\n",
       "                                                                    lower_text  \\\n",
       "0                                          i`d have responded, if i were going   \n",
       "1                                sooo sad i will miss you here in san diego!!!   \n",
       "2                                                    my boss is bullying me...   \n",
       "3                                               what interview! leave me alone   \n",
       "4   sons of ****, why couldn`t they put them on the releases we already bought   \n",
       "\n",
       "                                                                                                  tokens  \\\n",
       "0                                                      [i, `, d, have, responded, ,, if, i, were, going]   \n",
       "1                                         [sooo, sad, i, will, miss, you, here, in, san, diego, !, !, !]   \n",
       "2                                                                      [my, boss, is, bullying, me, ...]   \n",
       "3                                                                 [what, interview, !, leave, me, alone]   \n",
       "4  [sons, of, *, *, *, *, ,, why, couldn, `, t, they, put, them, on, the, releases, we, already, bought]   \n",
       "\n",
       "                                                   no_stops  \\\n",
       "0                                  [`, responded, ,, going]   \n",
       "1                    [sooo, sad, miss, san, diego, !, !, !]   \n",
       "2                                     [boss, bullying, ...]   \n",
       "3                              [interview, !, leave, alone]   \n",
       "4  [sons, *, *, *, *, ,, `, put, releases, already, bought]   \n",
       "\n",
       "                        no_stops_no_punct                   spacy_lemmas  \n",
       "0                      [responded, going]             [i`d, respond, go]  \n",
       "1           [sooo, sad, miss, san, diego]  [sooo, sad, miss, san, diego]  \n",
       "2                   [boss, bullying, ...]                  [boss, bully]  \n",
       "3               [interview, leave, alone]             [interview, leave]  \n",
       "4  [sons, put, releases, already, bought]  [son, couldn`t, release, buy]  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Define a function to use spacy to process our text\n",
    "def spacy_process(text):\n",
    "        \"\"\"Lemmatize tokens, lower case, remove punctuation, spaces, and stop words\"\"\"\n",
    "        doc = nlp_model(text)\n",
    "        processed_doc = [token.lemma_.lower() for token in doc if not token.is_punct and not token.is_space and not token.is_stop]\n",
    "        return processed_doc\n",
    "\n",
    "## process the tweets using the spacy function\n",
    "df['spacy_lemmas'] = df['text'].apply(spacy_process)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used spaCy to tokenize, lemmatize, and remove punctuation and stopwords from our text in one step!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the spaCy processed data is a little different than our previously processed data.  The text has been lemmatized and spaCy has a different list of stop words than NLTK.\n",
    "\n",
    "The learn platform has directions for how you can customize your spaCy stopword list and a function with more flexibility in how spaCy will process your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ngrams\n",
    "\n",
    "ngrams combine multiple words into tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import the ngrams function\n",
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.dothebouncy.com/smf',\n",
       " 'shameless',\n",
       " 'plug',\n",
       " 'good',\n",
       " 'rangers',\n",
       " 'forum',\n",
       " 'earth']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Isolate the first lemmatized document\n",
    "lemma_doc = df['spacy_lemmas'][5]\n",
    "lemma_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('http://www.dothebouncy.com/smf', 'shameless'),\n",
       " ('shameless', 'plug'),\n",
       " ('plug', 'good'),\n",
       " ('good', 'rangers'),\n",
       " ('rangers', 'forum'),\n",
       " ('forum', 'earth')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create bigrams\n",
    "list(ngrams(lemma_doc,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('http://www.dothebouncy.com/smf', 'shameless', 'plug'),\n",
       " ('shameless', 'plug', 'good'),\n",
       " ('plug', 'good', 'rangers'),\n",
       " ('good', 'rangers', 'forum'),\n",
       " ('rangers', 'forum', 'earth')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create trigrams\n",
    "list(ngrams(lemma_doc,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying `ngrams` to make a new column\n",
    "\n",
    "We need to make a function that returns a list of bigrams.  It won't work to just pass the ngrams function to `.apply()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a function to create bigrams\n",
    "def make_bigrams(doc):\n",
    "    bigrams = ngrams(doc, 2)\n",
    "    bigrams = list(bigrams)\n",
    "    return bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>length</th>\n",
       "      <th>lower_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>no_stops</th>\n",
       "      <th>no_stops_no_punct</th>\n",
       "      <th>spacy_lemmas</th>\n",
       "      <th>bigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>36</td>\n",
       "      <td>i`d have responded, if i were going</td>\n",
       "      <td>[i, `, d, have, responded, ,, if, i, were, going]</td>\n",
       "      <td>[`, responded, ,, going]</td>\n",
       "      <td>[responded, going]</td>\n",
       "      <td>[i`d, respond, go]</td>\n",
       "      <td>[(i`d, respond), (respond, go)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>negative</td>\n",
       "      <td>46</td>\n",
       "      <td>sooo sad i will miss you here in san diego!!!</td>\n",
       "      <td>[sooo, sad, i, will, miss, you, here, in, san, diego, !, !, !]</td>\n",
       "      <td>[sooo, sad, miss, san, diego, !, !, !]</td>\n",
       "      <td>[sooo, sad, miss, san, diego]</td>\n",
       "      <td>[sooo, sad, miss, san, diego]</td>\n",
       "      <td>[(sooo, sad), (sad, miss), (miss, san), (san, diego)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>negative</td>\n",
       "      <td>25</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>[my, boss, is, bullying, me, ...]</td>\n",
       "      <td>[boss, bullying, ...]</td>\n",
       "      <td>[boss, bullying, ...]</td>\n",
       "      <td>[boss, bully]</td>\n",
       "      <td>[(boss, bully)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>31</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>[what, interview, !, leave, me, alone]</td>\n",
       "      <td>[interview, !, leave, alone]</td>\n",
       "      <td>[interview, leave, alone]</td>\n",
       "      <td>[interview, leave]</td>\n",
       "      <td>[(interview, leave)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on the releases we already bought</td>\n",
       "      <td>negative</td>\n",
       "      <td>75</td>\n",
       "      <td>sons of ****, why couldn`t they put them on the releases we already bought</td>\n",
       "      <td>[sons, of, *, *, *, *, ,, why, couldn, `, t, they, put, them, on, the, releases, we, already, bought]</td>\n",
       "      <td>[sons, *, *, *, *, ,, `, put, releases, already, bought]</td>\n",
       "      <td>[sons, put, releases, already, bought]</td>\n",
       "      <td>[son, couldn`t, release, buy]</td>\n",
       "      <td>[(son, couldn`t), (couldn`t, release), (release, buy)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                          text  \\\n",
       "0                                          I`d have responded, if I were going   \n",
       "1                                Sooo SAD I will miss you here in San Diego!!!   \n",
       "2                                                    my boss is bullying me...   \n",
       "3                                               what interview! leave me alone   \n",
       "4   Sons of ****, why couldn`t they put them on the releases we already bought   \n",
       "\n",
       "  sentiment  length  \\\n",
       "0   neutral      36   \n",
       "1  negative      46   \n",
       "2  negative      25   \n",
       "3  negative      31   \n",
       "4  negative      75   \n",
       "\n",
       "                                                                    lower_text  \\\n",
       "0                                          i`d have responded, if i were going   \n",
       "1                                sooo sad i will miss you here in san diego!!!   \n",
       "2                                                    my boss is bullying me...   \n",
       "3                                               what interview! leave me alone   \n",
       "4   sons of ****, why couldn`t they put them on the releases we already bought   \n",
       "\n",
       "                                                                                                  tokens  \\\n",
       "0                                                      [i, `, d, have, responded, ,, if, i, were, going]   \n",
       "1                                         [sooo, sad, i, will, miss, you, here, in, san, diego, !, !, !]   \n",
       "2                                                                      [my, boss, is, bullying, me, ...]   \n",
       "3                                                                 [what, interview, !, leave, me, alone]   \n",
       "4  [sons, of, *, *, *, *, ,, why, couldn, `, t, they, put, them, on, the, releases, we, already, bought]   \n",
       "\n",
       "                                                   no_stops  \\\n",
       "0                                  [`, responded, ,, going]   \n",
       "1                    [sooo, sad, miss, san, diego, !, !, !]   \n",
       "2                                     [boss, bullying, ...]   \n",
       "3                              [interview, !, leave, alone]   \n",
       "4  [sons, *, *, *, *, ,, `, put, releases, already, bought]   \n",
       "\n",
       "                        no_stops_no_punct                   spacy_lemmas  \\\n",
       "0                      [responded, going]             [i`d, respond, go]   \n",
       "1           [sooo, sad, miss, san, diego]  [sooo, sad, miss, san, diego]   \n",
       "2                   [boss, bullying, ...]                  [boss, bully]   \n",
       "3               [interview, leave, alone]             [interview, leave]   \n",
       "4  [sons, put, releases, already, bought]  [son, couldn`t, release, buy]   \n",
       "\n",
       "                                                  bigrams  \n",
       "0                         [(i`d, respond), (respond, go)]  \n",
       "1   [(sooo, sad), (sad, miss), (miss, san), (san, diego)]  \n",
       "2                                         [(boss, bully)]  \n",
       "3                                    [(interview, leave)]  \n",
       "4  [(son, couldn`t), (couldn`t, release), (release, buy)]  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add bigrams to the df with .apply()\n",
    "df['bigrams'] = df['spacy_lemmas'].apply(make_bigrams)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the final data version for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the processed data\n",
    "df.to_csv('../Data/processed_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
